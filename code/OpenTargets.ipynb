{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba65450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "import pandas as pd \n",
    "df = pd.read_csv('../source/target_ids.csv')\n",
    "target_ids = df['target_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the list of target_id\n",
    "\n",
    "# URL for OpenTargets API\n",
    "url = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "\n",
    "def query_associated_diseases(target_id):\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{target_id}\") {{\n",
    "            id\n",
    "            approvedSymbol\n",
    "            associatedDiseases {{\n",
    "              count\n",
    "              rows {{\n",
    "                disease {{\n",
    "                  id\n",
    "                  name\n",
    "                }}\n",
    "                score\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Sending the POST request to the OpenTargets API\n",
    "    response = requests.post(url, json=query)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Ensure the response data is not None and has the required structure\n",
    "        if data and 'data' in data and 'target' in data['data']:\n",
    "            diseases = data['data']['target'].get('associatedDiseases', {}).get('rows', [])\n",
    "            approved_symbol = data['data']['target'].get('approvedSymbol', None)\n",
    "            return approved_symbol, diseases\n",
    "        else:\n",
    "            print(f\"No data found for target_id: {target_id}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Initialize the list for storing all the question-answer pairs\n",
    "all_question_answer_pairs = []\n",
    "\n",
    "# Iterate through the list of target_ids\n",
    "for target_id in target_ids:\n",
    "    result = query_associated_diseases(target_id)\n",
    "    \n",
    "    # Check if the result is None (i.e., the query failed or returned no data)\n",
    "    if result is None:\n",
    "        print(f\"No data returned for target_id: {target_id}\")\n",
    "        continue\n",
    "    \n",
    "    approved_symbol, associated_diseases = result\n",
    "\n",
    "    # Refined question formulation\n",
    "    question = f\"In the OpenTargets database, please retrieve the diseases associated with the target having target_id as {target_id} and approvedSymbol as {approved_symbol}, where the relevance score is greater than 0.5. Please provide the disease id, name, and relevance score for each associated disease.\"\n",
    "    \n",
    "    # Prepare the answer\n",
    "    answer = []\n",
    "    if associated_diseases:\n",
    "        for disease in associated_diseases:\n",
    "            score = disease['score']\n",
    "            if score > 0.5:  # Only include diseases with a relevance score greater than 0.5\n",
    "                answer.append({\n",
    "                    \"disease_id\": disease['disease']['id'],\n",
    "                    \"disease_name\": disease['disease']['name'],\n",
    "                    \"score\": score\n",
    "                })\n",
    "    else:\n",
    "        answer = \"no associated diseases found\"\n",
    "    \n",
    "    # Create the question-answer pair\n",
    "    output_data = {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "    # Add the question-answer pair to the list\n",
    "    all_question_answer_pairs.append(output_data)\n",
    "\n",
    "# Save all question-answer pairs into a single JSON file\n",
    "with open(\"associated_disease.json\", \"w\") as json_file:\n",
    "    json.dump(all_question_answer_pairs, json_file, indent=4)\n",
    "\n",
    "print(\"All question-answer pairs have been saved to associated_disease.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14f8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All question-answer pairs have been saved to target_tractability.json.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define a function to query the OpenTargets API for tractability information\n",
    "def query_target_tractability(target_id):\n",
    "    url = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "    \n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{target_id}\") {{\n",
    "            id\n",
    "            approvedSymbol\n",
    "            tractability {{\n",
    "              modality\n",
    "              label\n",
    "              value\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # Sending the POST request to the OpenTargets API\n",
    "    response = requests.post(url, json=query)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Ensure the response data is valid\n",
    "        if data and 'data' in data and 'target' in data['data']:\n",
    "            tractability = data['data']['target'].get('tractability', [])\n",
    "            approved_symbol = data['data']['target'].get('approvedSymbol', None)\n",
    "            return approved_symbol, tractability\n",
    "        else:\n",
    "            print(f\"No data found for target_id: {target_id}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initialize the list for storing question-answer pairs\n",
    "all_question_answer_pairs = []\n",
    "\n",
    "# Iterate through the list of target IDs\n",
    "for target_id in target_ids:\n",
    "    result = query_target_tractability(target_id)\n",
    "    \n",
    "    # Check if the result is None (i.e., the query failed or returned no data)\n",
    "    if result is None:\n",
    "        print(f\"No data returned for target_id: {target_id}\")\n",
    "        continue\n",
    "    \n",
    "    approved_symbol, tractability = result\n",
    "    \n",
    "    # Construct the updated question\n",
    "    question = f\"In the OpenTargets database, please retrieve the tractability information for the target with target ID {target_id} and approved symbol {approved_symbol}. For each modality, provide the label where the value is `True`.\"\n",
    "    \n",
    "    # Prepare the answer, filtering only tractability items with value True\n",
    "    answer = []\n",
    "    if tractability:\n",
    "        for item in tractability:\n",
    "            if item['value'] == True:  # Only include items where value is True\n",
    "                answer.append({\n",
    "                    \"modality\": item['modality'],\n",
    "                    \"label\": item['label'],\n",
    "                    \"value\": item['value']\n",
    "                })\n",
    "    else:\n",
    "        answer = \"No tractability information found.\"\n",
    "\n",
    "    # Create the question-answer pair\n",
    "    output_data = {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "    # Add the question-answer pair to the list\n",
    "    all_question_answer_pairs.append(output_data)\n",
    "\n",
    "# Save all question-answer pairs into a single JSON file\n",
    "with open(\"target_tractability.json\", \"w\") as json_file:\n",
    "    json.dump(all_question_answer_pairs, json_file, indent=4)\n",
    "\n",
    "print(\"All question-answer pairs have been saved to target_tractability.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, uuid, requests, openai\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "OT_ENDPOINT = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "\n",
    "def fetch_safety_liabilities(gene_id: str):\n",
    "    \"\"\"\n",
    "    返回 target 节点；若存在 death 事件仅保留 death，\n",
    "    否则只保留第一条 safetyLiability。\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{gene_id}\") {{\n",
    "            id\n",
    "            approvedSymbol\n",
    "            safetyLiabilities {{\n",
    "              event\n",
    "              eventId\n",
    "              biosamples {{\n",
    "                tissueLabel\n",
    "                tissueId\n",
    "              }}\n",
    "              effects {{\n",
    "                dosing\n",
    "                direction\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            OT_ENDPOINT,\n",
    "            json=query,\n",
    "            timeout=30,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        tgt = resp.json().get(\"data\", {}).get(\"target\")\n",
    "        if not tgt or not tgt.get(\"safetyLiabilities\"):\n",
    "            return None\n",
    "\n",
    "        # -------- 只保留 death 或首条 ----------\n",
    "        liabs = tgt[\"safetyLiabilities\"]\n",
    "        death_only = [li for li in liabs if li[\"event\"].lower() == \"death\"]\n",
    "        tgt[\"safetyLiabilities\"] = death_only or [liabs[0]]\n",
    "\n",
    "        return tgt\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[error] {gene_id} → {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 2. 构造 GPT Prompt ----------\n",
    "SYSTEM_MSG = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are an expert biomedical assistant.\\n\"\n",
    "        \"You will receive a **single safetyLiability** (only 'death' if present, \"\n",
    "        \"otherwise the first event) for a target.\\n\"\n",
    "        \"Return ONE JSON object with keys 'question' and 'answer'.\\n\"\n",
    "        \"• The 'question' must be a natural-language query limited to the OpenTargets database, \"\n",
    "        \"mentioning the target symbol+ID **and asking specifically about the provided event name**.\\n\"\n",
    "        \"• The 'answer' must respond concisely using ONLY the JSON, clearly listing tissues, dosing, etc. \"\n",
    "        \"If no biosample/effect field exists, state that absence.\\n\"\n",
    "        \"Output nothing except the JSON (no markdown fences).\"\n",
    "    )\n",
    "}\n",
    "def build_messages(raw_json: Dict) -> List[Dict]:\n",
    "    return [\n",
    "        SYSTEM_MSG,\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the OpenTargets JSON for one target:\\n```json\\n{json.dumps(raw_json, indent=2)}\\n```\"\n",
    "        }\n",
    "    ]\n",
    "def parse_json_or_raise(text: str) -> Dict:\n",
    "    clean = re.sub(r\"^```(?:json)?|```$\", \"\", text.strip(), flags=re.I|re.M).strip()\n",
    "    return json.loads(clean)\n",
    "\n",
    "def generate_qa(raw_json: Dict) -> Dict:\n",
    "    messages = build_messages(raw_json)\n",
    "    client = OpenAI(\n",
    "    base_url=\"https://api.chatanywhere.tech\",\n",
    "    api_key=' sk-OlimLcefr3MBSt08IrcZ9LrhP94qqni4w3u4qkOPFtAULcDD' \n",
    "    )\n",
    "    chat = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 或其他 GPT-4 级模型\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=400,\n",
    "        timeout=60\n",
    "    )\n",
    "    # 解析并返回模型输出（应已是合法 JSON）\n",
    "    return parse_json_or_raise(chat.choices[0].message.content)\n",
    "\n",
    "# ---------- 3. 主流程 ----------\n",
    "def build_benchmark(target_ids: List[str], outfile: str = \"target_safety.json\"):\n",
    "    qa_list = []\n",
    "\n",
    "    for tid in tqdm(target_ids, desc=\"Fetching & generating QA\"):\n",
    "        try:\n",
    "            result = fetch_safety_liabilities(tid)\n",
    "            if not result:                      # ← 无安全信息，直接跳过\n",
    "                continue\n",
    "\n",
    "            qa = generate_qa(result)\n",
    "            qa_list.append(qa)\n",
    "            time.sleep(1)                       # 避免速率限制\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[×] {tid} error: {e}\")\n",
    "\n",
    "    with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(qa_list, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nSaved {len(qa_list)} QA pairs → {outfile}\")\n",
    "    #read csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('target_ids.csv')\n",
    "# Convert the DataFrame to a list\n",
    "target_ids = df['target_id'].tolist()\n",
    "build_benchmark(target_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5007ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "import pandas as pd \n",
    "df = pd.read_csv('../source/target_ids.csv')\n",
    "target_ids = df['target_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2712ca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8027d874b8d04607880818649b3d4155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building OpenTargets QA:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ ENSG00000242950 has no diseases ≥0.5\n",
      "⚠️ ENSG00000101144 has no diseases ≥0.5\n",
      "\n",
      "✅ Saved 119 samples → opentargets_qa_dataset.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build_opentargets_qa.py\n",
    "-----------------------\n",
    "For each Ensembl target_id:\n",
    "• query OpenTargets for associated diseases\n",
    "• single GPT call creates a natural question + filter params\n",
    "• output QA dataset with tool_calls\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, hashlib, requests\n",
    "from typing import List\n",
    "from tqdm.auto import tqdm\n",
    "from openai import AzureOpenAI   # 若用 Azure → from openai import AzureOpenAI\n",
    "\n",
    "# ---------- OpenAI client ----------\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "# ========= 0. Azure OpenAI 配置 =========\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4.1-noah\"\n",
    "\n",
    "# ---------- OpenTargets GraphQL ----------\n",
    "OT_URL = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "\n",
    "def fetch_associated_diseases(target_id: str, min_score=0.5) -> tuple[str, List[dict]]:\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{target_id}\") {{\n",
    "            approvedSymbol\n",
    "            associatedDiseases {{\n",
    "              rows {{\n",
    "                disease {{ id name }}\n",
    "                score\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "    r = requests.post(OT_URL, json=query, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"data\"][\"target\"]\n",
    "    symbol = data[\"approvedSymbol\"]\n",
    "    rows = [\n",
    "        d for d in data[\"associatedDiseases\"][\"rows\"]\n",
    "        if d[\"score\"] >= min_score\n",
    "    ]\n",
    "    return symbol, rows\n",
    "\n",
    "# ---------- GPT prompt ----------\n",
    "SYSTEM = (\n",
    "    \"You are creating English QA pairs for an agent dataset. \"\n",
    "    \"Return a JSON object with:\\n\"\n",
    "    \"• question – ONE natural sentence that asks for the diseases associated \"\n",
    "    \"  with a given target in OpenTargets. It must mention the target’s Ensembl \"\n",
    "    \"  ID, its approved symbol, and the minimum relevance score.\\n\"\n",
    "    \"• filter   – a JSON object containing only the keys that appear in the \"\n",
    "    \"  question: target_id, min_score. \"\n",
    "    \"Return ONLY the JSON.\"\n",
    ")\n",
    "\n",
    "def gpt_build_question(target_id: str, symbol: str, min_score: float) -> dict:\n",
    "    user = (\n",
    "        f\"target_id={target_id}; symbol={symbol}; min_score={min_score}\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"system\", \"content\": SYSTEM},\n",
    "                  {\"role\":\"user\",   \"content\": user}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# ---------- main ----------\n",
    "# read the csv file\n",
    "import pandas as pd \n",
    "df = pd.read_csv('../source/target_ids.csv')\n",
    "target_ids = df['target_id'].tolist()\n",
    "\n",
    "samples = []\n",
    "\n",
    "for tid in tqdm(target_ids, desc=\"Building OpenTargets QA\"):\n",
    "    try:\n",
    "        symbol, diseases = fetch_associated_diseases(tid, min_score=0.5)\n",
    "        if not diseases:\n",
    "            tqdm.write(f\"⚠️ {tid} has no diseases ≥0.5\")\n",
    "            continue\n",
    "\n",
    "        gpt_out  = gpt_build_question(tid, symbol, 0.5)\n",
    "        question = gpt_out[\"question\"].strip()\n",
    "        filt     = gpt_out[\"filter\"]\n",
    "\n",
    "        # --- answer list ---\n",
    "        answer = [\n",
    "            {\n",
    "                \"disease_id\":   d[\"disease\"][\"id\"],\n",
    "                \"disease_name\": d[\"disease\"][\"name\"],\n",
    "                \"score\":        d[\"score\"]\n",
    "            } for d in diseases\n",
    "        ]\n",
    "\n",
    "        # --- sample ---\n",
    "        samples.append({\n",
    "            \"id\": hashlib.md5(tid.encode()).hexdigest()[:16],\n",
    "            \"question\": question,\n",
    "            \"tool_calls\": [{\n",
    "                \"tool\": \"opentargets.search\",\n",
    "                \"params\": filt                   # {\"target_id\": \"...\", \"min_score\": 0.5}\n",
    "            }],\n",
    "            \"answer\": answer\n",
    "        })\n",
    "        time.sleep(0.8)  # rate-limit\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"❌ {tid} failed: {e}\")\n",
    "\n",
    "with open(\"opentargets_qa_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"dataset\": samples}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(samples)} samples → opentargets_qa_dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c46f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2003ba762d4f52bdf996767478ebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building OT-Tractability QA:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 121 samples → ot_tractability_qa.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build_opentargets_tractability_qa.py\n",
    "------------------------------------\n",
    "Generate QA samples for OT tractability:\n",
    "• question  (natural, single sentence, “In the OpenTargets platform, …”)\n",
    "• tool_calls (opentargets.tractability with target_id, value=True)\n",
    "• answer     (modality + label list)\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, hashlib, requests\n",
    "from typing import List\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI         # 若用 Azure -> AzureOpenAI\n",
    "\n",
    "# ---------------- OpenAI client ----------------\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "# ========= 0. Azure OpenAI 配置 =========\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4.1-noah\"\n",
    "SLEEP    = 1.0                 # 速率限制\n",
    "\n",
    "# ---------------- OpenTargets GraphQL -----------\n",
    "OT_URL = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "\n",
    "def fetch_tractability(target_id: str) -> tuple[str, List[dict]]:\n",
    "    \"\"\"返回 (approved_symbol, [{modality,label,value=True}, ...])\"\"\"\n",
    "    q = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{target_id}\") {{\n",
    "            approvedSymbol\n",
    "            tractability {{\n",
    "              modality\n",
    "              label\n",
    "              value\n",
    "            }}\n",
    "          }}\n",
    "        }}\"\"\"\n",
    "    }\n",
    "    r = requests.post(OT_URL, json=q, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    trg = r.json()[\"data\"][\"target\"]\n",
    "    rows = [d for d in trg[\"tractability\"] if d[\"value\"] is True]\n",
    "    return trg[\"approvedSymbol\"], rows\n",
    "\n",
    "# ---------------- GPT prompt -------------------\n",
    "SYSTEM = (\n",
    "    \"You are creating English QA pairs for an agent dataset. \"\n",
    "    \"Return **only** a JSON object with two keys:\\n\"\n",
    "    \"• question – ONE natural sentence that starts with \"\n",
    "    \"\\\"In the OpenTargets platform,\\\" and asks for the tractability \"\n",
    "    \"information for a given target. It must state the target's Ensembl ID \"\n",
    "    \"and its approved symbol, and require that `value` is True. \"\n",
    "    \"Do NOT reveal any JSON keys or answer.\\n\"\n",
    "    \"• filter   – an object that includes exactly the keys explicitly \"\n",
    "    \"mentioned in the question. Here they are target_id and value. \"\n",
    "    \"`value` must be true.\\n\\n\"\n",
    "    \"Return ONLY the JSON object.\"\n",
    ")\n",
    "\n",
    "def gpt_question_and_filter(tid: str, symbol: str) -> dict:\n",
    "    user = f\"target_id={tid}; symbol={symbol}\"\n",
    "    rsp  = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"system\",\"content\":SYSTEM},\n",
    "                  {\"role\":\"user\",\"content\":user}],\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return json.loads(rsp.choices[0].message.content)\n",
    "\n",
    "# ---------------- build dataset ----------------\n",
    "import pandas as pd \n",
    "df = pd.read_csv('../source/target_ids.csv')\n",
    "target_ids = df['target_id'].tolist()\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for tid in tqdm(target_ids, desc=\"Building OT-Tractability QA\"):\n",
    "    try:\n",
    "        symbol, rows = fetch_tractability(tid)\n",
    "        if not rows:\n",
    "            tqdm.write(f\"⚠️ {tid}: no tractability value=True\")\n",
    "            continue\n",
    "\n",
    "        gpt_out  = gpt_question_and_filter(tid, symbol)\n",
    "        question = gpt_out[\"question\"].strip()\n",
    "        filt     = gpt_out[\"filter\"]          # {\"target_id\": \"...\", \"value\": true}\n",
    "\n",
    "        # 保底：若模型忘写前缀，加上\n",
    "        if not question.lower().startswith(\"in the opentargets\"):\n",
    "            question = \"In the OpenTargets platform, \" + question[0].lower() + question[1:]\n",
    "\n",
    "        answer = [{\"modality\": r[\"modality\"], \"label\": r[\"label\"]} for r in rows]\n",
    "\n",
    "        dataset.append({\n",
    "            \"id\": hashlib.md5(tid.encode()).hexdigest()[:16],\n",
    "            \"question\": question,\n",
    "            \"tool_calls\": [{\n",
    "                \"tool\":   \"opentargets.tractability\",\n",
    "                \"params\": filt          # 只含 target_id & value=True\n",
    "            }],\n",
    "            \"answer\": answer\n",
    "        })\n",
    "        time.sleep(SLEEP)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"❌ {tid} failed: {e}\")\n",
    "\n",
    "with open(\"ot_tractability_qa.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"dataset\": dataset}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(dataset)} samples → ot_tractability_qa.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "968b2b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab31a0453aa457fbf6e0bd1c15366f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating OT-safety QA:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 2 samples → ot_safety_qa.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build_ot_safety_qa.py\n",
    "---------------------\n",
    "Generate QA pairs about safety liabilities (death / first event) for targets.\n",
    "Each sample: question + tool_calls(opentargets.safety) + answer\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, hashlib, re, requests, pandas as pd\n",
    "from typing import List, Dict,Optional\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI   # 若用 Azure → AzureOpenAI\n",
    "\n",
    "# ---------------- OpenAI client ----------------\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "# ========= 0. Azure OpenAI 配置 =========\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4.1-noah\"\n",
    "SLEEP    = 1.0                 # 速率限制\n",
    "RATE    = 1.0               # 简单限速\n",
    "\n",
    "# -------- OpenTargets GraphQL -----\n",
    "OT_URL = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
    "\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "def pick_best_row(rows: List[Dict]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    返回包含细节的最佳 safetyLiability 条目：\n",
    "    - 先筛出 biosamples 或 effects 非空者\n",
    "    - 其中若有 'death' 优先\n",
    "    - 否则随机取第一条\n",
    "    \"\"\"\n",
    "    # ① 有细节的\n",
    "    detail_rows = [r for r in rows if r.get(\"biosamples\") or r.get(\"effects\")]\n",
    "    if not detail_rows:\n",
    "        return None\n",
    "\n",
    "    # ② death 优先\n",
    "    for r in detail_rows:\n",
    "        if r[\"event\"].lower() == \"death\":\n",
    "            return r\n",
    "    return detail_rows[0]\n",
    "\n",
    "\n",
    "def fetch_safety(target_id: str) -> Optional[Dict]:\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          target(ensemblId: \"{target_id}\") {{\n",
    "            approvedSymbol\n",
    "            safetyLiabilities {{\n",
    "              event\n",
    "              eventId\n",
    "              biosamples {{ tissueLabel tissueId }}\n",
    "              effects    {{ dosing direction }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\"\"\"\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(OT_URL, json=query, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        target = resp.json()[\"data\"][\"target\"]\n",
    "        rows   = target[\"safetyLiabilities\"]\n",
    "        if not rows:\n",
    "            return None\n",
    "\n",
    "        best = pick_best_row(rows)\n",
    "        if best is None:               # 没有任何细节 → 跳过\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            \"symbol\":     target[\"approvedSymbol\"],\n",
    "            \"event\":      best[\"event\"],\n",
    "            \"biosamples\": best.get(\"biosamples\", []),\n",
    "            \"effects\":    best.get(\"effects\", [])\n",
    "        }\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[error] {target_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -------- GPT prompt -------------\n",
    "SYSTEM = (\n",
    "    \"You build English QA pairs for a biomedical agent dataset.\\n\"\n",
    "    \"Return **only** a JSON object with keys:\\n\"\n",
    "    \"• question – ONE natural sentence that starts with \"\n",
    "    \"\\\"In the OpenTargets platform,\\\" and asks specifically for the given \"\n",
    "    \"safety liability event of the target (using its Ensembl ID and symbol).\\n\"\n",
    "    \"• filter   – object with exactly the keys that appear in the question. \"\n",
    "    \"Here they are `target_id` and `event`.\\n\"\n",
    "    \"• answer   – a JSON object with keys 'event', 'biosamples', 'effects'.\"\n",
    "    \"(tissues, dosing, direction; say 'none' if missing).\\n\"\n",
    "    \"No markdown fences.\"\n",
    ")\n",
    "\n",
    "def gpt_create(sample: Dict, tid: str) -> Dict:\n",
    "    user = json.dumps({\n",
    "        \"target_id\": tid,\n",
    "        \"symbol\":    sample[\"symbol\"],\n",
    "        \"event\":     sample[\"event\"],\n",
    "        \"biosamples\": sample[\"biosamples\"],\n",
    "        \"effects\":    sample[\"effects\"]\n",
    "    }, ensure_ascii=False)\n",
    "    rsp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\":\"system\",\"content\":SYSTEM},\n",
    "                  {\"role\":\"user\",  \"content\":user}],\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return json.loads(rsp.choices[0].message.content)\n",
    "\n",
    "# -------- Build dataset ----------\n",
    "def build_dataset(target_ids: List[str], out=\"ot_safety_qa.json\"):\n",
    "    data = []\n",
    "    for tid in tqdm(target_ids, desc=\"Generating OT-safety QA\"):\n",
    "        sample = fetch_safety(tid)\n",
    "        if not sample:          # 无有效事件\n",
    "            continue\n",
    "        try:\n",
    "            gpt_out   = gpt_create(sample, tid)\n",
    "            q         = gpt_out[\"question\"].strip()\n",
    "            filt      = gpt_out[\"filter\"]       # {\"target_id\": \"...\", \"event\": \"...\"}\n",
    "            answer    = gpt_out[\"answer\"]\n",
    "\n",
    "            if not q.lower().startswith(\"in the opentargets\"):\n",
    "                q = \"In the OpenTargets platform, \" + q[0].lower() + q[1:]\n",
    "\n",
    "            data.append({\n",
    "                \"id\": hashlib.md5((tid+sample['event']).encode()).hexdigest()[:16],\n",
    "                \"question\": q,\n",
    "                \"tool_calls\": [{\n",
    "                    \"tool\": \"opentargets.safety\",\n",
    "                    \"params\": filt\n",
    "                }],\n",
    "                \"answer\": answer\n",
    "            })\n",
    "            time.sleep(RATE)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[GPT error] {tid}: {e}\")\n",
    "\n",
    "    with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"dataset\": data}, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n✅ Saved {len(data)} samples → {out}\")\n",
    "\n",
    "# -------- run --------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('../source/target_ids.csv')\n",
    "    target_ids = df['target_id'].tolist()[:3]\n",
    "    build_dataset(target_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d344851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2955f14d7546ba8a51a4a71b4a8a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Polishing & adding tools:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅  Saved 31 QA pairs → enriched_qa.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "polish_and_enrich_ot_safety_qa.py\n",
    "---------------------------------\n",
    "Read raw_qa.json  (question+answer only)  →\n",
    "Call GPT once per item →\n",
    "Return polished question + id + tool_calls →\n",
    "Write enriched_qa.json\n",
    "\"\"\"\n",
    "\n",
    "import json, hashlib, os, time, re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI      # <— Azure 用户换成 AzureOpenAI 并加 endpoint\n",
    "\n",
    "# ============ OpenAI 配置 =============\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4.1-noah\"\n",
    "SLEEP    = 1.0                 # 速率限制\n",
    "# ============ GPT 提示 =============\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are refining biomedical QA data. \"\n",
    "    \"Input: a QA object with 'question' and 'answer'.\\n\"\n",
    "    \"Step A  Re-write the question into ONE natural English sentence that \"\n",
    "    \"starts with “In the OpenTargets database,” or “Within OpenTargets,” and \"\n",
    "    \"clearly mentions both the target symbol (e.g. HTR3A) and the event name \"\n",
    "    \"(e.g. emesis). Preserve original meaning.\\n\"\n",
    "    \"Step B  Extract exactly those two pieces of information:\\n\"\n",
    "    \"    • symbol : target gene/protein approved symbol\\n\"\n",
    "    \"    • event  : safety-liability event (verbatim)\\n\"\n",
    "    \"Step C  Return a JSON object:\\n\"\n",
    "    \"{\\n\"\n",
    "    \"  \\\"id\\\"        : first 16 hex of sha256(polished_question),\\n\"\n",
    "    \"  \\\"question\\\"  : <polished_question>,\\n\"\n",
    "    \"  \\\"tool_calls\\\": [ {\\\"tool\\\":\\\"opentargets.safety\\\", \"\n",
    "    \"                     \\\"params\\\": {\\\"symbol\\\": <symbol>, \\\"event\\\": <event>} } ],\\n\"\n",
    "    \"  \\\"answer\\\"    : <unchanged answer> \\n\"\n",
    "    \"}\\n\"\n",
    "    \"No markdown fences, no extra keys.\"\n",
    ")\n",
    "\n",
    "def sha16(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode()).hexdigest()[:16]\n",
    "\n",
    "def polish_and_enrich(item: Dict) -> Optional[Dict]:\n",
    "    \"\"\"Call GPT once, return enriched object (or None on failure).\"\"\"\n",
    "    user_msg = json.dumps(item, ensure_ascii=False)\n",
    "    rsp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.25,\n",
    "        timeout=60\n",
    "    )\n",
    "    # 直接解析为字典\n",
    "    enriched = json.loads(rsp.choices[0].message.content)\n",
    "\n",
    "    # ——— 保险：若 GPT 忘记计算 id，就补算一次 ———\n",
    "    if \"id\" not in enriched or not enriched[\"id\"]:\n",
    "        enriched[\"id\"] = sha16(enriched[\"question\"])\n",
    "\n",
    "    return enriched\n",
    "\n",
    "\n",
    "# ============ 主流程 ============\n",
    "RAW_FILE  = \"../dataset/target_safety.json\"            # ← 你的原始文件\n",
    "OUT_FILE  = \"enriched_qa.json\"\n",
    "SLEEP_SEC = 0.5                      # 简易限速\n",
    "\n",
    "raw_data: List[Dict] = json.loads(Path(RAW_FILE).read_text(encoding=\"utf-8\"))\n",
    "enriched: List[Dict] = []\n",
    "\n",
    "for item in tqdm(raw_data, desc=\"Polishing & adding tools\"):\n",
    "    try:\n",
    "        new_item = polish_and_enrich(item)\n",
    "        if new_item:\n",
    "            enriched.append(new_item)\n",
    "        time.sleep(SLEEP_SEC)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"❌  Failed on item: {e}\")\n",
    "\n",
    "# 保存\n",
    "Path(OUT_FILE).write_text(json.dumps({\"dataset\": enriched},\n",
    "                                     ensure_ascii=False, indent=2))\n",
    "print(f\"\\n✅  Saved {len(enriched)} QA pairs → {OUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
