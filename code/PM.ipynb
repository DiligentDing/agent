{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfda83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9699f352fee4076ad01247ccff68be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating QA samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 100 unique samples → pubmed_qa_dataset_100.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "azure_pubmed_qa_builder_100.py\n",
    "------------------------------\n",
    "Generate 100 de-duplicated PubMed-QA samples (English) with Azure OpenAI + PubMed.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json, time, random, hashlib, requests, itertools\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Set\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ========== 0. Azure OpenAI ==========\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4.1-noah\"          # ← your deployment name\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    ")\n",
    "\n",
    "# ========== 1. PubMed helpers ==========\n",
    "PUBMED_BASE = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "\n",
    "def pubmed_search(term: str, retmax: int, api_key: Optional[str]) -> List[str]:\n",
    "    params = {\"db\": \"pubmed\", \"term\": term,\n",
    "              \"retmax\": retmax, \"retmode\": \"json\", \"sort\": \"pub+date\"}\n",
    "    if api_key:\n",
    "        params[\"api_key\"] = api_key\n",
    "    r = requests.get(f\"{PUBMED_BASE}/esearch.fcgi\", params=params, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"esearchresult\"][\"idlist\"]\n",
    "\n",
    "def fetch_metadata(pmids: List[str], api_key: Optional[str]) -> Dict[str, Dict[str, Any]]:\n",
    "    if not pmids:\n",
    "        return {}\n",
    "    params = {\"db\": \"pubmed\", \"id\": \",\".join(pmids), \"retmode\": \"json\"}\n",
    "    if api_key:\n",
    "        params[\"api_key\"] = api_key\n",
    "    r = requests.get(f\"{PUBMED_BASE}/esummary.fcgi\", params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    result = r.json()[\"result\"]\n",
    "    return {pid: result[pid] for pid in pmids if pid in result}\n",
    "\n",
    "# ========== 2. GPT paraphrase ==========\n",
    "SYSTEM_MSG = (\"You are a helpful assistant that creates natural English questions \"\n",
    "              \"for a biomedical literature QA dataset.\")\n",
    "\n",
    "def paraphrase_query(meta: Dict[str, Any]) -> str:\n",
    "    title = meta.get(\"title\", \"\")\n",
    "    journal = meta.get(\"fulljournalname\", \"\")\n",
    "    year = meta.get(\"pubdate\", \"\").split(\" \")[0]\n",
    "    author = meta.get(\"sortfirstauthor\", \"\")\n",
    "    prompt = (\n",
    "        \"Rewrite the following search intent into one concise, natural English \"\n",
    "        \"question (do not mention PubMed, E-utilities, or search syntax):\\n\\n\"\n",
    "        f\"Intent: Find the unique PMID of the article whose title contains \"\n",
    "        f\"“{title}”, first author {author}, published in {journal} in {year}.\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=AZURE_DEPLOYMENT_NAME,\n",
    "        messages=[{\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.6,\n",
    "        max_tokens=128,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# ========== 3. Query builder ==========\n",
    "def build_unique_query(meta: Dict[str, Any]) -> str:\n",
    "    title_phrase = meta.get(\"title\", \"\").split(\":\")[0]\n",
    "    author = meta.get(\"sortfirstauthor\", \"\")\n",
    "    year = meta.get(\"pubdate\", \"\").split(\" \")[0]\n",
    "    return f\"\\\"{title_phrase}\\\"[ti] AND {author}[au] AND {year}[dp]\"\n",
    "\n",
    "def make_tool_call(term: str) -> Dict[str, Any]:\n",
    "    return {\"tool\": \"pubmed.search\", \"params\": {\"term\": term, \"retmax\": 1}}\n",
    "\n",
    "# ========== 4. Seed sampling & dataset ==========\n",
    "MESH_TOPICS = [\n",
    "    \"oncology\", \"neurology\", \"cardiology\", \"immunology\", \"gastroenterology\",\n",
    "    \"endocrinology\", \"pulmonology\", \"dermatology\", \"psychiatry\", \"genetics\"\n",
    "]\n",
    "\n",
    "def sample_seed_pmids(topic: str, n: int, api_key: Optional[str]) -> List[str]:\n",
    "    term = f\"{topic}[MeSH Major Topic] AND 2023:2025[pdat]\"\n",
    "    return pubmed_search(term, retmax=n, api_key=api_key)\n",
    "\n",
    "def build_dataset(target_n: int = 100,\n",
    "                  ncbi_key: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "    dataset: List[Dict[str, Any]] = []\n",
    "    used_pmids: Set[str] = set()\n",
    "\n",
    "    # round-robin over MESH_TOPICS to increase diversity\n",
    "    topic_cycle = itertools.cycle(MESH_TOPICS)\n",
    "\n",
    "    with tqdm(total=target_n, desc=\"Generating QA samples\") as pbar:\n",
    "        while len(dataset) < target_n:\n",
    "            topic = next(topic_cycle)\n",
    "            seed_pmids = sample_seed_pmids(topic, n=20, api_key=ncbi_key)\n",
    "\n",
    "            # Remove already used PMIDs\n",
    "            seed_pmids = [pid for pid in seed_pmids if pid not in used_pmids]\n",
    "            if not seed_pmids:\n",
    "                continue\n",
    "\n",
    "            metas = fetch_metadata(seed_pmids, api_key=ncbi_key)\n",
    "            for pid in seed_pmids:\n",
    "                if pid in used_pmids or pid not in metas:\n",
    "                    continue\n",
    "\n",
    "                meta = metas[pid]\n",
    "                term = build_unique_query(meta)\n",
    "                question = paraphrase_query(meta)\n",
    "\n",
    "                dataset.append({\n",
    "                    \"id\": hashlib.md5(term.encode()).hexdigest()[:16],\n",
    "                    \"question\": question,\n",
    "                    \"tool_calls\": [make_tool_call(term)],\n",
    "                    \"answer\": [pid]\n",
    "                })\n",
    "                used_pmids.add(pid)\n",
    "                pbar.update(1)\n",
    "\n",
    "                # NCBI 速率限制：≤3 次 / 秒\n",
    "                time.sleep(0.34)\n",
    "\n",
    "                if len(dataset) >= target_n:\n",
    "                    break\n",
    "    return dataset\n",
    "\n",
    "# ========== 5. Save ==========\n",
    "def save_json(data: List[Dict[str, Any]], path: str) -> None:\n",
    "    Path(path).write_text(json.dumps({\"dataset\": data},\n",
    "                                     ensure_ascii=False, indent=2))\n",
    "    print(f\"\\n✅ Saved {len(data)} unique samples → {path}\")\n",
    "\n",
    "# ========== 6. Run ==========\n",
    "if __name__ == \"__main__\":\n",
    "    ncbi_key = os.getenv(\"NCBI_API_KEY\")\n",
    "    qa_data = build_dataset(target_n=100, ncbi_key=ncbi_key)\n",
    "    save_json(qa_data, \"pubmed_qa_dataset_100.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
