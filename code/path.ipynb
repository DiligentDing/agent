{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe66016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在重复路径，共 1541 条：\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# 替换为你的 JSON 文件路径\n",
    "json_path = '../source/clinical-paths.json'\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 提取所有 path 列表并转为元组，便于比较\n",
    "path_list = []\n",
    "for item in data:\n",
    "    if \"path\" in item:\n",
    "        path_tuple = tuple(item[\"path\"])\n",
    "        path_list.append(path_tuple)\n",
    "\n",
    "# 统计重复项\n",
    "from collections import Counter\n",
    "path_counter = Counter(path_list)\n",
    "\n",
    "# 找出重复的路径\n",
    "duplicates = [path for path, count in path_counter.items() if count > 1]\n",
    "\n",
    "# 输出结果\n",
    "if duplicates:\n",
    "    print(\"存在重复路径，共 {} 条：\\n\".format(len(duplicates)))\n",
    "else:\n",
    "    print(\"没有重复路径。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 替换为你的 JSON 文件路径\n",
    "json_path = '../source/clinical-paths.json'\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 提取所有 path 列表并转为元组，便于比较\n",
    "path_list = []\n",
    "for item in data:\n",
    "    if \"path\" in item:\n",
    "        path_tuple = tuple(item[\"path\"])\n",
    "        path_list.append(path_tuple)\n",
    "\n",
    "path_list=list(set(path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be82238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the unique paths to json file\n",
    "with open(\"path.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(path_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d0e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_path_length_stats(path_list):\n",
    "    \"\"\"\n",
    "    统计并打印路径长度分布，格式如 `len 22:238`\n",
    "    \"\"\"\n",
    "    # 1️⃣ 统计每条路径的长度\n",
    "    length_counts = Counter(len(p) for p in path_list)\n",
    "\n",
    "    # 2️⃣ 按长度从大到小排序并打印\n",
    "    for length, count in sorted(length_counts.items(), key=lambda x: -x[0]):\n",
    "        print(f\"len {length}:{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3891d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4879647167f949efa7cc4325c41cf40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating QA:   0%|          | 0/1937 [00:00<?, ?case/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅  已生成 1937 条问答 → ../benchmark/oncology_case_qa_all.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate_oncology_qa.py\n",
    "───────────────────────\n",
    "Read a list of treatment-path tuples, ask GPT to synthesize a realistic\n",
    "clinical vignette + Q-A for each, and save the results as JSON.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import os, json, time\n",
    "from openai import OpenAI\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"  \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"gpt-4.1-noah\"                          # 换成你的部署名\n",
    "OUT_FILE   = \"../benchmark/oncology_case_qa_all.json\"\n",
    "\n",
    "SYS_PROMPT = \"\"\" \n",
    "你是一位临床肿瘤学专家，同时也是人工智能模型评测设计师，负责构建高质量的医学问答题集，用于系统评估大语言模型在肿瘤学领域的理解能力、推理能力与临床判断能力。\n",
    "\n",
    "我将提供一段实体瘤诊疗路径的关键节点（术前评估、分期、治疗、随访等）。\n",
    "\n",
    "你的任务是：基于该路径中的知识，构造一对具有挑战性的、高信息质量的问答（question 和 answer），用于评估模型是否具备真实临床决策场景下的应对能力。\n",
    "\n",
    "【总体要求】：\n",
    "\n",
    "1. **问题必须是信息封闭且结构聚焦的**：\n",
    "   - 所有必要的背景信息必须清晰完整地写在题干中；\n",
    "   - 严禁使用“该患者”、“上述路径”、“推荐中”等上下文代词或引用性语句；\n",
    "   - 问题必须聚焦于**一个**临床判断挑战点，不可同时问多个维度；\n",
    "   - 问题必须能被独立理解与回答。\n",
    "\n",
    "2. **问题类型必须具有挑战性**，请从下列类型中选择其一，并围绕一个**临床决策判断点**展开构造：\n",
    "\n",
    "- **隐含前提推理**  \n",
    "  判断某种治疗或方案是否隐含特定的临床状态（如分期、分型、分子特征）；\n",
    "  - ✴ 示例：患者接受 CDK4/6 抑制剂联合 AI，是否意味着其为 HR+/HER2- 型且绝经后？\n",
    "\n",
    "- **排他性判断**  \n",
    "  判断一个决策是否同时排除了另一种人群或路径；\n",
    "  - ✴ 示例：若满足免 ALND 条件，是否意味着接受术前治疗的患者不适用？\n",
    "\n",
    "- **前提缺失挑战**  \n",
    "  若某项关键前提在问题设定中缺失，应推断推荐是否仍成立；\n",
    "  - ✴ 示例：若未说明 BRCA 状态，能否合理使用 PARP 抑制剂？\n",
    "\n",
    "- **例外情境判断**  \n",
    "  在临床特殊人群（如高龄、器官功能不全、合并症）中判断某治疗是否仍可行；\n",
    "  - ✴ 示例：高龄合并严重肺病的患者是否仍适合术后放疗？\n",
    "\n",
    "- **方案选择权衡**  \n",
    "  给出两个可行治疗方案，要求比较优先级或适用场景；\n",
    "  - ✴ 示例：在伴有肝转移的 HR+ 晚期患者中，应优先使用化疗还是 CDK4/6 抑制剂？\n",
    "\n",
    "- **适用边界判断**  \n",
    "  探索某治疗策略的适用边界是否被超出，或边界条件改变后是否仍成立；\n",
    "  - ✴ 示例：若 SLN 阳性数量为 3 个而非 2 个，是否仍可省略 ALND？\n",
    "\n",
    "- **治疗顺序逻辑**  \n",
    "  检查治疗方案之间的前后顺序是否合理，是否存在逻辑冲突；\n",
    "  - ✴ 示例：若术后立即推荐系统治疗，是否表示可跳过放疗阶段？\n",
    "\n",
    "- **病理/分期假设识别**  \n",
    "  判断某策略是否基于特定病理类型、分子特征或临床分期前提；\n",
    "  - ✴ 示例：推荐 PARP 抑制剂是否默认适用于 BRCA 突变人群？\n",
    "\n",
    "3. **答案必须权威、简洁、精准**：\n",
    "   - 用语专业，应符合当前临床主流实践或指南精神；\n",
    "   - 字数建议控制在 60–100 字；\n",
    "   - 严禁模糊说法，如“可能”、“可以考虑”、“建议讨论”等不确定表达；\n",
    "   - 答案应体现清晰的医学逻辑或治疗判断路径。\n",
    "\n",
    "4. 输出格式必须为合法 JSON（仅包含对象本身，前后不得加 ``` 或 “json” 标记）：\n",
    "{\n",
    "  \"question\": \"……\",\n",
    "  \"answer\":  \"……\"\n",
    "}\n",
    "⚠️ **最终 question 与 answer 必须用英文撰写。**\n",
    "\"\"\"\n",
    "\n",
    "# # ─── 2. 统一系统提示 ──────────────────────────────────────────────────\n",
    "# SYS_PROMPT = (\n",
    "#     \"你是一名资深肿瘤科医师。\\n\"\n",
    "#     \"我将提供一段实体瘤诊疗路径的关键节点（术前评估、分期、治疗、随访等）。\\n\"\n",
    "#     \"请基于这些信息构思【一个合理的临床病历场景】，\"\n",
    "#     \"并用中文生成一对问答：\\n\"\n",
    "#     \"• question：病例描述 + 提问（例如分期判断、下一步治疗、基因检测选择等）。\\n\"\n",
    "#     \"• answer：权威、简明的标准答案。\\n\\n\"\n",
    "#     \"⚠️ 仅返回合法 JSON，对象键严格为 question 和 answer；不得输出多余文本。\"\n",
    "# )\n",
    "import hashlib\n",
    "\n",
    "def make_id(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode()).hexdigest()[:16]\n",
    "\n",
    "def build_tool_calls(path_nodes: list[str]) -> list[dict]:\n",
    "    return [{\n",
    "        \"tool\": \"oncology.path_query\",\n",
    "        \"params\": { \"nodes\": path_nodes }\n",
    "    }]\n",
    "\n",
    "def ask_gpt(messages):\n",
    "\n",
    "    resp=client.chat.completions.create(\n",
    "        model= MODEL_NAME,\n",
    "        messages     = messages,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "from tqdm.auto import tqdm   # auto 能在终端/Jupyter 智能切换\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "# tqdm 会自动显示当前进度、耗时、速度等\n",
    "for i, path in enumerate(tqdm(path_list, desc=\"Generating QA\", unit=\"case\"), 1):\n",
    "    path_txt = \"；\".join(path)\n",
    "    user_msg = (\n",
    "        f\"\"\"\n",
    "        以下为诊疗路径摘要：\n",
    "        \\\"\\\"\\\"\n",
    "        {path_txt}\n",
    "        \\\"\\\"\\\"\n",
    "\n",
    "        请基于该路径中的知识，构造一对完全自包含的问题与答案。\n",
    "\n",
    "        你提出的问题应围绕以下结构展开：  \n",
    "        - 问边界（引入边界模糊值）  \n",
    "        - 问特殊（引入特殊情境,如并发症或干扰信息）  \n",
    "        - 问优先级（两个治疗选项如何选择）  \n",
    "        - 问前提（决策是否基于特定假设） 这个是不是不行？\n",
    "\n",
    "        问题中不得引用“路径”、“建议”、“该患者”、“该指南”等字眼，而应将必要背景完整表达于题干中。\n",
    "        \"\"\"    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": user_msg},\n",
    "    ]\n",
    "\n",
    "    # raw = ask_gpt(messages)  # ▶ 和 print 语句都无需了\n",
    "\n",
    "    try:\n",
    "        gpt_out = json.loads(ask_gpt(messages).strip())\n",
    "\n",
    "        # 重新组织字段顺序（id 放首位）\n",
    "        qa = OrderedDict()\n",
    "        qa[\"id\"]         = make_id(gpt_out.get(\"question\", \"\"))\n",
    "        qa[\"question\"]   = gpt_out.get(\"question\", \"\")\n",
    "        qa[\"tool_calls\"] = build_tool_calls(path)\n",
    "        qa[\"answer\"]     = gpt_out.get(\"answer\", \"\")\n",
    "        qa_pairs.append(qa)\n",
    "    except Exception as e:\n",
    "        qa_pairs.append(OrderedDict([\n",
    "            (\"id\", make_id(str(e))),\n",
    "            (\"question\", \"FORMAT_ERROR\"),\n",
    "            (\"tool_calls\", build_tool_calls(path)),\n",
    "            (\"answer\", str(e))\n",
    "        ]))\n",
    "\n",
    "    time.sleep(0.5)  # 轻限流，保留\n",
    "\n",
    "\n",
    "with Path(OUT_FILE).open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\"dataset\": qa_pairs},   # <- 统一外层键\n",
    "        f,\n",
    "        ensure_ascii=False,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "print(f\"\\n✅  已生成 {len(qa_pairs)} 条问答 → {OUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289ee588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def call_slot_fill_tool(prompt, tool, language=\"en\"):\n",
    "    \"\"\"\n",
    "    Question -> query parameters, used to query Noah AI database, text in json out\n",
    "    Expected time to run: < 15s\n",
    "    Output: {'result': 'success', 'data': <dict>}\n",
    "    Available tools include:\n",
    "    [\n",
    "        \"General-Inference\",\n",
    "        \"Medical-Search\",\n",
    "        \"Web-Search\",\n",
    "        \"Clinical-Trial-Result-Analysis\",\n",
    "        \"Drug-Analysis\",\n",
    "        \"Catalyst-Event-Analysis\"\n",
    "    \"\"\"\n",
    "    noah_api_url = f\"https://staging.noahai.co/api/tool_test/\"\n",
    "    body = {\"language\":\"en\", \"user_prompt\":prompt, \"tool\":tool, \"slot_fill\":True}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Token ab2af44c17490f0c3c3b221b0f6fc2c20d62590a\"}\n",
    "    response = requests.post(noah_api_url, data=json.dumps(body), headers=headers, timeout=30, allow_redirects=True, verify=False)\n",
    "    try: ret = response.json()\n",
    "    except: ret = response.text\n",
    "    return ret\n",
    "\n",
    "def call_tool(prompt, tool, language=\"en\"):\n",
    "    \"\"\"\n",
    "    Question -> report, text in text out\n",
    "    Expected time to run: ~2min\n",
    "    Output: {'result': 'success', 'data': <txt>}\n",
    "    Available tools include:\n",
    "    [\n",
    "        \"General-Inference\",\n",
    "        \"Medical-Search\",\n",
    "        \"Web-Search\",\n",
    "        \"Clinical-Trial-Result-Analysis\",\n",
    "        \"Drug-Analysis\",\n",
    "        \"Catalyst-Event-Analysis\"\n",
    "    \"\"\"\n",
    "    noah_api_url = f\"https://staging.noahai.co/api/tool_test/\"\n",
    "    body = {\"language\": language, \"user_prompt\":prompt, \"tool\":tool, \"slot_fill\":False}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Token ab2af44c17490f0c3c3b221b0f6fc2c20d62590a\"}\n",
    "    response = requests.post(noah_api_url, data=json.dumps(body), headers=headers, timeout=240, allow_redirects=True, verify=False)\n",
    "    try: ret = response.json()\n",
    "    except: ret = response.text\n",
    "    return ret\n",
    "\n",
    "def call_agent(prompt, language=\"en\"):\n",
    "    \"\"\"\n",
    "    Question -> report, text in text out\n",
    "    Expected time to run: ~10-12min\n",
    "    Output: {'result': 'success', 'data': <txt>}\n",
    "    \"\"\"\n",
    "    noah_api_url = f\"https://staging.noahai.co/api/tool_test/\"\n",
    "    body = {\"language\": language, \"user_prompt\":prompt, \"tool\": \"agent\"}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Token ab2af44c17490f0c3c3b221b0f6fc2c20d62590a\"}\n",
    "    response = requests.post(noah_api_url, data=json.dumps(body), headers=headers, timeout=1200, allow_redirects=True, verify=False)\n",
    "    try: ret = response.json()\n",
    "    except: ret = response.text\n",
    "    return ret\n",
    "\n",
    "#print(call_slot_fill_tool('减肥药的最新竞争格局', 'Drug-Analysis'))\n",
    "# print(call_tool('减肥药的最新竞争格局', 'Drug-Analysis'))\n",
    "# print(call_agent('减肥药的最新竞争格局'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb7b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../dataset/hard_qa.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_pairs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda65896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Noah agent answering: 100%|██████████| 169/169 [00:00<00:00, 438908.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished. Answers saved to /home/xinding/dingxin/Agent/MAIA/evaluation/noah/model_answers.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# file: gen_with_noah_agent.py\n",
    "# ====================================\n",
    "import os, json, time, pathlib, tqdm\n",
    "import requests\n",
    "import os, json, time, pathlib, tqdm\n",
    "from openai import AzureOpenAI\n",
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "#os.environ[\"OPENAI_API_KEY\"] = 'sk-4jnd9yjoIXnQRQ5SXR2b3bVO1d3sHtuyegGMzAl6awSWDRNn' \n",
    "#os.environ['OPENAI_BASE_URL'] = 'https://api2.aigcbest.top/v1' \n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'sk-OlimLcefr3MBSt08IrcZ9LrhP94qqni4w3u4qkOPFtAULcDD' \n",
    "# os.environ['OPENAI_BASE_URL'] = 'https://api.chatanywhere.tech' \n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "# ========= 0. Azure OpenAI 配置 =========\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "JUDGE_MODEL     = \"gpt-4.1-noah\"          # 亦可用同一模型评分\n",
    "TEMP            = 0.1               # 回答温度\n",
    "RATE_LIMIT_S    = 1.2               # 简单限流间隔\n",
    "# ---------- Noah API 调用封装 ---------- #\n",
    "NOAH_TOKEN = \"b85ee49cde4db576eee2522c6c340e7f967537e2\"\n",
    "NOAH_URL   = \"https://staging.noahai.co/api/tool_test/\"\n",
    "\n",
    "def call_agent(prompt:str, language:str=\"cn\", timeout:int=1200):\n",
    "    \"\"\"\n",
    "    Question -> report, text in text out\n",
    "    Expected time to run: ~10-12min\n",
    "    Output: {'result': 'success', 'data': <txt>}\n",
    "    \"\"\"\n",
    "    body = {\"language\": language, \"user_prompt\": prompt, \"tool\": \"agent\"}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": f\"Token {NOAH_TOKEN}\",\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        NOAH_URL,\n",
    "        data=json.dumps(body),\n",
    "        headers=headers,\n",
    "        timeout=timeout,\n",
    "        allow_redirects=True,\n",
    "        verify=False,          # staging 证书自签；生产环境请去掉\n",
    "    )\n",
    "    try:\n",
    "        js = resp.json()\n",
    "    except Exception:\n",
    "        raise RuntimeError(f\"Non-JSON response: {resp.text[:200]}\")\n",
    "\n",
    "    if js.get(\"result\") != \"success\":\n",
    "        raise RuntimeError(f\"Noah API error: {js}\")\n",
    "    return js.get(\"data\", \"\").strip()\n",
    "\n",
    "\n",
    "# ---------- 路径 & 数据 ---------- #\n",
    "qa_path   = pathlib.Path(\"../dataset/hard_qa.json\")\n",
    "out_dir   = pathlib.Path(\"../evaluation/noah\");  out_dir.mkdir(exist_ok=True)\n",
    "out_path  = out_dir / \"model_answers.json\"\n",
    "\n",
    "with qa_path.open(encoding=\"utf-8\") as f:\n",
    "    qa_pairs = json.load(f)\n",
    "\n",
    "# 断点续跑\n",
    "model_answers = {}\n",
    "if out_path.exists():\n",
    "    model_answers = json.load(out_path.open())\n",
    "\n",
    "# ---------- 主循环 ---------- #\n",
    "RATE_LIMIT_S  = 2.0    # Noah staging 建议≥2s/req；必要时再增大\n",
    "RETRY_WAIT_S  = 15\n",
    "MAX_RETRY     = 3\n",
    "\n",
    "for idx, qa in enumerate(tqdm.tqdm(qa_pairs, desc=\"Noah agent answering\")):\n",
    "    key = str(idx)\n",
    "    if key in model_answers:               # 已完成 → 跳过\n",
    "        continue\n",
    "\n",
    "    raw_q = qa[\"question\"]\n",
    "    if not isinstance(raw_q, str):\n",
    "        raw_q = json.dumps(raw_q, ensure_ascii=False)\n",
    "    question = raw_q\n",
    "    for attempt in range(1, MAX_RETRY + 1):\n",
    "        try:\n",
    "            ans = call_agent(question)\n",
    "            model_answers[key] = ans\n",
    "            break                          # 成功则退出 retry 循环\n",
    "        except Exception as e:\n",
    "            print(f\"[Agent error #{attempt} @ {idx}] {e}\")\n",
    "            if attempt == MAX_RETRY:\n",
    "                model_answers[key] = \"\"    # 记录空串，后续可手动补跑\n",
    "            else:\n",
    "                time.sleep(RETRY_WAIT_S)\n",
    "\n",
    "    # 每 10 条落盘一次\n",
    "    if idx % 10 == 9:\n",
    "        json.dump(model_answers, out_path.open(\"w\", encoding=\"utf-8\"),\n",
    "                  ensure_ascii=False, indent=2)\n",
    "\n",
    "    time.sleep(RATE_LIMIT_S)\n",
    "\n",
    "# ---------- 最终保存 ---------- #\n",
    "json.dump(model_answers, out_path.open(\"w\", encoding=\"utf-8\"),\n",
    "          ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nFinished. Answers saved to {out_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c27af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judging answers: 100%|██████████| 169/169 [04:31<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Summary ===\n",
      "Samples evaluated : 169/169\n",
      "Average score     : 3.75 / 5\n",
      "Score distribution: {1: 3, 2: 17, 3: 38, 4: 72, 5: 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========= 3. 调用 Judge 评分 =========\n",
    "import re\n",
    "\n",
    "scores_path = out_dir / \"judge_scores.json\"\n",
    "judge_scores = json.load(open(scores_path)) if scores_path.exists() else {}\n",
    "\n",
    "judge_prompt_tpl = \"\"\"You are an impartial medical board examiner.\n",
    "Score the following model answer against the reference answer on a scale of 0–5,\n",
    "using this rubric:\n",
    "5 = identical clinical content, no major omissions or errors;\n",
    "4 = nearly complete, minor omissions;\n",
    "3 = partial, some omissions or inaccuracies;\n",
    "2 = limited coverage or notable errors;\n",
    "1 = largely incorrect or irrelevant;\n",
    "0 = blank or nonsense.\n",
    "\n",
    "Only reply with the score (0–5) followed by a short 1–2 sentence justification.\n",
    "\n",
    "For example, \"4: The model answer is almost identical to the reference answer, but it misses a few minor details.\"\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Reference answer:\n",
    "{ref_answer}\n",
    "\n",
    "Model answer:\n",
    "{model_answer}\n",
    "\"\"\"\n",
    "\n",
    "# 只初始化一次，循环里复用\n",
    "judge_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "for idx, qa in enumerate(tqdm.tqdm(qa_pairs, desc=\"Judging answers\")):\n",
    "    key = str(idx)\n",
    "\n",
    "    # 已评分 → 跳过\n",
    "    if key in judge_scores:\n",
    "        continue\n",
    "\n",
    "    model_ans = model_answers.get(key, \"\")\n",
    "    # ---------- 缺失或空白：直接跳过 ----------\n",
    "    if not model_ans.strip():\n",
    "        continue\n",
    "\n",
    "    prompt = judge_prompt_tpl.format(\n",
    "        question     = qa[\"question\"],\n",
    "        ref_answer   = qa[\"answer\"],\n",
    "        model_answer = model_ans\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        resp = judge_client.chat.completions.create(\n",
    "            model       = JUDGE_MODEL,\n",
    "            temperature = 0,\n",
    "            max_tokens  = 120,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert clinical examiner.\"},\n",
    "                {\"role\": \"user\",   \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "        raw = resp.choices[0].message.content.strip()\n",
    "\n",
    "        m = re.search(r\"\\b([0-5](?:\\.\\d+)?)\\b\", raw)\n",
    "        if not m:                          # 未匹配到分数 → 留待手动或下次重跑\n",
    "            print(f\"[Judge format error @ {idx}] {raw}\")\n",
    "            continue\n",
    "\n",
    "        score = float(m.group(1))\n",
    "        judge_scores[key] = {\"score\": score, \"explanation\": raw}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Judge error @ {idx}] {e}. Retrying next run…\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # 每 10 条持久化一次\n",
    "    if len(judge_scores) % 10 == 0:\n",
    "        json.dump(judge_scores, open(scores_path, \"w\", encoding=\"utf-8\"),\n",
    "                  ensure_ascii=False, indent=2)\n",
    "        time.sleep(RATE_LIMIT_S)\n",
    "\n",
    "# 最终保存\n",
    "json.dump(judge_scores, open(scores_path, \"w\", encoding=\"utf-8\"),\n",
    "          ensure_ascii=False, indent=2)\n",
    "\n",
    "# ========= 4. 汇总统计 =========\n",
    "scores = [v[\"score\"] for v in judge_scores.values()]\n",
    "if scores:                                   # 避免除零\n",
    "    avg = sum(scores) / len(scores)\n",
    "else:\n",
    "    avg = 0.0\n",
    "\n",
    "# 参与评测的总样本 = 有非空答案的条目数\n",
    "total_evaluable = sum(\n",
    "    1 for i in range(len(qa_pairs))\n",
    "    if model_answers.get(str(i), \"\").strip()\n",
    ")\n",
    "\n",
    "dist = defaultdict(int)\n",
    "for s in scores:\n",
    "    dist[int(s)] += 1\n",
    "\n",
    "print(\"\\n=== Evaluation Summary ===\")\n",
    "print(f\"Samples evaluated : {len(scores)}/{total_evaluable}\")\n",
    "print(f\"Average score     : {avg:.2f} / 5\")\n",
    "print(\"Score distribution:\", dict(sorted(dist.items())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd11f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# file: gen_with_noah_agent.py\n",
    "# ====================================\n",
    "import os, json, time, pathlib, tqdm\n",
    "import requests\n",
    "import os, json, time, pathlib, tqdm\n",
    "from openai import AzureOpenAI\n",
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "#os.environ[\"OPENAI_API_KEY\"] = 'sk-4jnd9yjoIXnQRQ5SXR2b3bVO1d3sHtuyegGMzAl6awSWDRNn' \n",
    "#os.environ['OPENAI_BASE_URL'] = 'https://api2.aigcbest.top/v1' \n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'sk-OlimLcefr3MBSt08IrcZ9LrhP94qqni4w3u4qkOPFtAULcDD' \n",
    "# os.environ['OPENAI_BASE_URL'] = 'https://api.chatanywhere.tech' \n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "# ========= 0. Azure OpenAI 配置 =========\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "JUDGE_MODEL     = \"gpt-4.1-noah\"          # 亦可用同一模型评分\n",
    "TEMP            = 0.1               # 回答温度\n",
    "RATE_LIMIT_S    = 1.2               # 简单限流间隔\n",
    "# ---------- Noah API 调用封装 ---------- #\n",
    "NOAH_TOKEN = \"b85ee49cde4db576eee2522c6c340e7f967537e2\"\n",
    "NOAH_URL   = \"https://staging.noahai.co/api/tool_test/\"\n",
    "\n",
    "def call_agent(prompt:str, language:str=\"cn\", timeout:int=1200):\n",
    "    \"\"\"\n",
    "    Question -> report, text in text out\n",
    "    Expected time to run: ~10-12min\n",
    "    Output: {'result': 'success', 'data': <txt>}\n",
    "    \"\"\"\n",
    "    body = {\"language\": language, \"user_prompt\": prompt, \"tool\": \"agent\"}\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": f\"Token {NOAH_TOKEN}\",\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        NOAH_URL,\n",
    "        data=json.dumps(body),\n",
    "        headers=headers,\n",
    "        timeout=timeout,\n",
    "        allow_redirects=True,\n",
    "        verify=False,          # staging 证书自签；生产环境请去掉\n",
    "    )\n",
    "    try:\n",
    "        js = resp.json()\n",
    "    except Exception:\n",
    "        raise RuntimeError(f\"Non-JSON response: {resp.text[:200]}\")\n",
    "\n",
    "    if js.get(\"result\") != \"success\":\n",
    "        raise RuntimeError(f\"Noah API error: {js}\")\n",
    "    return js.get(\"data\", \"\").strip()\n",
    "\n",
    "\n",
    "# ---------- 路径 & 数据 ---------- #\n",
    "qa_path   = pathlib.Path(\"../dataset/hard_qa.json\")\n",
    "out_dir   = pathlib.Path(\"../evaluation/noah\");  out_dir.mkdir(exist_ok=True)\n",
    "out_path  = out_dir / \"model_answers.json\"\n",
    "\n",
    "with qa_path.open(encoding=\"utf-8\") as f:\n",
    "    qa_pairs = json.load(f)\n",
    "\n",
    "# 断点续跑\n",
    "model_answers = {}\n",
    "if out_path.exists():\n",
    "    model_answers = json.load(out_path.open())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
