{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf519421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('valid_clinical_trials_20250417.csv', header=None)\n",
    "nctid= df.iloc[:, 0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "783b8783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from: https://clinicaltrials.gov/api/v2/studies?filter.ids=NCT00027300,NCT01712490,NCT00099788,NCT00215800,NCT00005947,NCT00065442,NCT03566043,NCT00097591,NCT00157209,NCT00088530,NCT00129142,NCT00111319,NCT01133704,NCT00424047,NCT00093158,NCT00123253,NCT00004205,NCT00056160,NCT00089570,NCT00024440,NCT00688740,NCT00117676,NCT00116805,NCT00314951,NCT00071799,NCT00071487,NCT00154102,NCT00179660,NCT00262080,NCT00213135,NCT00257608,NCT00274651,NCT00294723,NCT00307437,NCT00327691,NCT00126724,NCT00391872,NCT00308139,NCT00289640,NCT00289978,NCT00287729,NCT00287716,NCT00333775,NCT00325195,NCT00364013,NCT05428969,NCT00321464,NCT00395135,NCT00603902,NCT00358150,NCT00357279,NCT00355134,NCT00343564,NCT00364923,NCT00262600,NCT00152386,NCT00113607,NCT02873936,NCT00542555,NCT00340834,NCT03207009,NCT00420212,NCT00451451,NCT00337103,NCT00135408,NCT00524277,NCT00412984,NCT00413036,NCT00050778,NCT00134563,NCT00468728,NCT00125034,NCT00467844,NCT00298038,NCT00297258,NCT00403767,NCT00318461,NCT00554216,NCT00521053,NCT01265849,NCT00509145,NCT00530348,NCT00573443,NCT00532779,NCT00553787,NCT00454818,NCT00991211,NCT00446680,NCT00567255,NCT00511238,NCT00530816,NCT00518882,NCT00590187,NCT00471497,NCT00627926,NCT00339183,NCT00637273,NCT00641056,NCT00623636,NCT00000560&pageSize=100\n",
      "Fetching data from: https://clinicaltrials.gov/api/v2/studies?filter.ids=NCT00027300,NCT01712490,NCT00099788,NCT00215800,NCT00005947,NCT00065442,NCT03566043,NCT00097591,NCT00157209,NCT00088530,NCT00129142,NCT00111319,NCT01133704,NCT00424047,NCT00093158,NCT00123253,NCT00004205,NCT00056160,NCT00089570,NCT00024440,NCT00688740,NCT00117676,NCT00116805,NCT00314951,NCT00071799,NCT00071487,NCT00154102,NCT00179660,NCT00262080,NCT00213135,NCT00257608,NCT00274651,NCT00294723,NCT00307437,NCT00327691,NCT00126724,NCT00391872,NCT00308139,NCT00289640,NCT00289978,NCT00287729,NCT00287716,NCT00333775,NCT00325195,NCT00364013,NCT05428969,NCT00321464,NCT00395135,NCT00603902,NCT00358150,NCT00357279,NCT00355134,NCT00343564,NCT00364923,NCT00262600,NCT00152386,NCT00113607,NCT02873936,NCT00542555,NCT00340834,NCT03207009,NCT00420212,NCT00451451,NCT00337103,NCT00135408,NCT00524277,NCT00412984,NCT00413036,NCT00050778,NCT00134563,NCT00468728,NCT00125034,NCT00467844,NCT00298038,NCT00297258,NCT00403767,NCT00318461,NCT00554216,NCT00521053,NCT01265849,NCT00509145,NCT00530348,NCT00573443,NCT00532779,NCT00553787,NCT00454818,NCT00991211,NCT00446680,NCT00567255,NCT00511238,NCT00530816,NCT00518882,NCT00590187,NCT00471497,NCT00627926,NCT00339183,NCT00637273,NCT00641056,NCT00623636,NCT00000560&pageSize=100&pageToken=NF0g5JCAkPcgxQM\n",
      "         NCT ID  Acronym Overall Status  Start Date  \\\n",
      "0   NCT00056160  Unknown      COMPLETED  2003-01-01   \n",
      "1   NCT00637273  Unknown      COMPLETED     2008-01   \n",
      "2   NCT00262080  Unknown      COMPLETED  2005-12-31   \n",
      "3   NCT00446680  Unknown      COMPLETED     2007-03   \n",
      "4   NCT00097591  Unknown      COMPLETED     2004-11   \n",
      "..          ...      ...            ...         ...   \n",
      "95  NCT00521053  Unknown      COMPLETED     2007-09   \n",
      "96  NCT00123253  Unknown      COMPLETED     2005-06   \n",
      "97  NCT00005947  Unknown      COMPLETED     1999-11   \n",
      "98  NCT00590187  Unknown      COMPLETED     2007-12   \n",
      "99  NCT00553787  Unknown      COMPLETED     2007-11   \n",
      "\n",
      "                                           Conditions  \\\n",
      "0                                    Multiple Myeloma   \n",
      "1                            Type 2 Diabetes Mellitus   \n",
      "2                         Hereditary Angioedema (HAE)   \n",
      "3                                     Cystic Fibrosis   \n",
      "4   Coronary Arteriosclerosis, Acute Coronary Synd...   \n",
      "..                                                ...   \n",
      "95                                           Melanoma   \n",
      "96                      HIV Infections, Lipodystrophy   \n",
      "97                                    Prostate Cancer   \n",
      "98                             Acute Myeloid Leukemia   \n",
      "99                           Obesity, Type 2 Diabetes   \n",
      "\n",
      "                                        Interventions  \\\n",
      "0                              CC-5013, Dexamethasone   \n",
      "1   exenatide once weekly, sitagliptin, pioglitazo...   \n",
      "2         ecallantide, Phosphate Buffer Saline (PBS),   \n",
      "3                                   Mannitol, placebo   \n",
      "4                              Prasugrel, Clopidogrel   \n",
      "..                                                ...   \n",
      "95                   PV-10 (10% rose bengal disodium)   \n",
      "96                                             TH9507   \n",
      "97                              sipuleucel-T, Placebo   \n",
      "98  Sapacitabine, Arm A, Sapacitabine, Arm B, Sapa...   \n",
      "99                          VI-0521, VI-0521, VI-0521   \n",
      "\n",
      "                                            Locations Primary Completion Date  \\\n",
      "0   Hoover - United States, Duarte - United States...              2005-11-01   \n",
      "1   Peoria - United States, Artesia - United State...                 2009-02   \n",
      "2                             Wheaton - United States              2005-12-31   \n",
      "3   Sydney - Australia, Sydney - Australia, Brisba...                 2010-05   \n",
      "4                        Indianapolis - United States                 2007-07   \n",
      "..                                                ...                     ...   \n",
      "95  San Francisco - United States, Louisville - Un...                 2010-05   \n",
      "96  Los Angeles - United States, Palm Springs - Un...                 2006-11   \n",
      "97  Duarte - United States, Loma Linda - United St...                 2004-09   \n",
      "98  Birmingham - United States, Los Angeles - Unit...              2018-12-01   \n",
      "99  Birmingham - United States, Ridgefield - Unite...                 2009-06   \n",
      "\n",
      "   Study First Post Date Last Update Post Date      Study Type  Phases  \n",
      "0             2003-03-07            2017-10-19  INTERVENTIONAL  PHASE3  \n",
      "1             2008-03-17            2015-04-07  INTERVENTIONAL  PHASE3  \n",
      "2             2005-12-06            2021-06-11  INTERVENTIONAL  PHASE3  \n",
      "3             2007-03-13            2010-06-25  INTERVENTIONAL  PHASE3  \n",
      "4             2004-11-25            2010-09-16  INTERVENTIONAL  PHASE3  \n",
      "..                   ...                   ...             ...     ...  \n",
      "95            2007-08-27            2014-08-25  INTERVENTIONAL  PHASE2  \n",
      "96            2005-07-22            2013-11-27  INTERVENTIONAL  PHASE3  \n",
      "97            2004-03-05            2010-11-01  INTERVENTIONAL  PHASE3  \n",
      "98            2008-01-10            2024-06-04  INTERVENTIONAL  PHASE2  \n",
      "99            2007-11-06            2012-09-10  INTERVENTIONAL  PHASE3  \n",
      "\n",
      "[100 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Initial URL for the first API call\n",
    "base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "params = {\n",
    "    \"filter.ids\":\",\".join(nctid),\n",
    "    \"pageSize\": 100\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Loop until there is no nextPageToken\n",
    "while True:\n",
    "    # Print the current URL (for debugging purposes)\n",
    "    print(\"Fetching data from:\", base_url + '?' + '&'.join([f\"{k}={v}\" for k, v in params.items()]))\n",
    "    \n",
    "    # Send a GET request to the API\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Parse JSON response\n",
    "        studies = data.get('studies', [])  # Extract the list of studies\n",
    "\n",
    "        # Loop through each study and extract specific information\n",
    "        for study in studies[:100]:\n",
    "            # Safely access nested keys\n",
    "            nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "            overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "            startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "            conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "            acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "            # Extract interventions safely\n",
    "            interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "            interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "            \n",
    "            # Extract locations safely\n",
    "            locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "            locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "            \n",
    "            # Extract dates and phases\n",
    "            primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "            studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "            lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "            studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "            phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "\n",
    "            # Append the data to the list as a dictionary\n",
    "            data_list.append({\n",
    "                \"NCT ID\": nctId,\n",
    "                \"Acronym\": acronym,\n",
    "                \"Overall Status\": overallStatus,\n",
    "                \"Start Date\": startDate,\n",
    "                \"Conditions\": conditions,\n",
    "                \"Interventions\": interventions,\n",
    "                \"Locations\": locations,\n",
    "                \"Primary Completion Date\": primaryCompletionDate,\n",
    "                \"Study First Post Date\": studyFirstPostDate,\n",
    "                \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                \"Study Type\": studyType,\n",
    "                \"Phases\": phases\n",
    "            })\n",
    "\n",
    "        # Check for nextPageToken and update the params or break the loop\n",
    "        nextPageToken = data.get('nextPageToken')\n",
    "        if nextPageToken:\n",
    "            params['pageToken'] = nextPageToken  # Set the pageToken for the next request\n",
    "        else:\n",
    "            break  # Exit the loop if no nextPageToken is present\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv(\"clinical_trials_data_complete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f63435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-4jnd9yjoIXnQRQ5SXR2b3bVO1d3sHtuyegGMzAl6awSWDRNn' \n",
    "os.environ['OPENAI_BASE_URL'] = 'https://api2.aigcbest.top/v1' \n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a098a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_retrieval_question(data):\n",
    "    conditions = data.get(\"Conditions\", \"\")\n",
    "    interventions = data.get(\"Interventions\", \"\")\n",
    "    overall_status = data.get(\"Overall Status\", \"\")\n",
    "    locations = data.get(\"Locations\", \"\")\n",
    "    \n",
    "    prompt = (\n",
    "        \"Please generate a precise search question based on the following clinical trial information so that the literature can be accurately matched in the clinical trial database.\\n\"\n",
    "        f\"Conditions：{conditions}\\n\"\n",
    "        f\"interventions：{interventions}\\n\"\n",
    "        f\"overall_status：{overall_status}\\n\\n\"\n",
    "        f\"locations：{locations}\\n\\n\"\n",
    "        \"Please output in the following format：\\n\"\n",
    "        \"Question: Please find clinical trials on ClinicalTrials.gov related to Unresectable Hilar Cholangiocarcinoma, with interventions REMS+TAI and SEMS+TAI, and status COMPLETED. The trial was conducted in Nanjing - China.Please answer the NCT ID.\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[ \n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in clinical trial information retrieval, good at formulating precise and natural questions\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=250\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        # 尝试获取以“问题:”开头的文本\n",
    "        match = re.search(r\"Question:\\s*(.*)\", content, re.DOTALL)\n",
    "        if match:\n",
    "            question_text = match.group(0).strip()\n",
    "            return question_text\n",
    "        else:\n",
    "            return content.strip()\n",
    "    except Exception as e:\n",
    "        print(\"调用 GPT API 生成检索问题出错:\", e)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0d4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"clinical_trials_data_complete.csv\")\n",
    "# df to json list\n",
    "data_list = df.to_dict(orient='records')\n",
    "\n",
    "def construct_answer(data):\n",
    "    \"\"\"\n",
    "    构造答案，答案直接采用文献信息，包括标题、PMID、发表日期和溯源链接。\n",
    "    \"\"\"\n",
    "    nctid = data.get(\"NCT ID\", \"\")\n",
    "    return {\n",
    "        \"NCT ID\": nctid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "474e3cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 100/100 [04:13<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共生成 100 条问答，已保存至 qa_pairs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm  # 可选，用于显示进度条\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for record in tqdm(data_list, desc=\"Processing records\"):\n",
    "    # 生成检索问题\n",
    "    question = generate_retrieval_question(record)\n",
    "    # 构造答案\n",
    "    answer = construct_answer(record)\n",
    "    # 将问答对加入列表\n",
    "    qa_pairs.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# 将结果写入 JSON 文件\n",
    "with open(\"qa_pairs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_pairs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"共生成 {len(qa_pairs)} 条问答，已保存至 qa_pairs.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d70bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from openai import AzureOpenAI\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb982a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate_clinical_trials_qa.py\n",
    "———————————————\n",
    "Read a CSV of clinical-trial metadata, call GPT to create natural-language\n",
    "ClinicalTrials.gov questions, and save QA pairs to JSON.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import openai\n",
    "\n",
    "# ========== 配置 ==========\n",
    "csv_path   = \"./source/clinical_trials_data_complete.csv\"\n",
    "json_out   = \"qa_pairs.json\"\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # 或直接写明字符串\n",
    "model_name = \"gpt-4.1-noah\"                         # 也可用 gpt-3.5-turbo-0125\n",
    "sleep_sec  = 1.2                              # 速率限制：可按需要调整\n",
    "# =========================\n",
    "\n",
    "# 把日期 \"2003-01-01\" -> \"January 2003\"，\"2008-01\" -> \"2008\"\n",
    "def pretty_date(d):\n",
    "    try:\n",
    "        # 处理空值 / NaN\n",
    "        if pd.isna(d): \n",
    "            return \"\"\n",
    "        d = str(d).strip()\n",
    "        # 只有年份或“YYYY-MM”\n",
    "        if len(d) <= 7:\n",
    "            return d\n",
    "        return parser.parse(d).strftime(\"%B %Y\")\n",
    "    except Exception:\n",
    "        return d\n",
    "\n",
    "# 给 GPT 的 system 提示（一次即可，不必重复发送）\n",
    "SYSTEM_MSG = (\n",
    "    \"You create concise, natural search questions for ClinicalTrials.gov. \"\n",
    "    \"The question must:\\n\"\n",
    "    \"1. Begin with 'In ClinicalTrials.gov,' (or similar) to specify scope.\\n\"\n",
    "    \"2. Cite 3-6 key fields (status, phase, study type, start date, condition, \"\n",
    "    \"main interventions, countries/regions) that uniquely pinpoint the trial.\\n\"\n",
    "    \"3. Avoid long exhaustive lists; summarize interventions/locations clearly \"\n",
    "    \"and naturally (e.g., 'compared drug A with placebo', 'across sites in the United States and Canada').\\n\"\n",
    "    \"4. Use fluent English; no SQL-like phrasing.\\n\"\n",
    "    \"Return ONLY the single sentence question.\"\n",
    ")\n",
    "\n",
    "def build_user_prompt(row):\n",
    "    \"\"\"给 GPT 的 user 消息，包含原始字段，提示它写问题\"\"\"\n",
    "    fields = {\n",
    "        \"NCT_ID\":             row[\"NCT ID\"],\n",
    "        \"Acronym\":            row.get(\"Acronym\", \"\"),\n",
    "        \"Overall_Status\":     row[\"Overall Status\"],\n",
    "        \"Phase\":              row.get(\"Phases\", \"\"),\n",
    "        \"Study_Type\":         row.get(\"Study Type\", \"\"),\n",
    "        \"Start_Date\":         pretty_date(row[\"Start Date\"]),\n",
    "        \"Conditions\":         row[\"Conditions\"],\n",
    "        \"Interventions\":      row[\"Interventions\"],\n",
    "        \"Locations\":          row[\"Locations\"],\n",
    "    }\n",
    "    # 让 GPT 按我们的规则写问题，但别透露 NCT_ID\n",
    "    return (\n",
    "        \"Write one natural-language question that would let a person retrieve \"\n",
    "        \"this exact clinical trial on ClinicalTrials.gov. Use the metadata JSON below; \"\n",
    "        \"do NOT mention the NCT_ID, do NOT list every city; keep it concise.\\n\\n\"\n",
    "        f\"metadata = {json.dumps(fields, ensure_ascii=False)}\"\n",
    "    )\n",
    "\n",
    "def ask_gpt(metadata_row):\n",
    "    \"\"\"向 GPT 发送聊天消息并返回问题字符串\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "            {\"role\": \"user\",   \"content\": build_user_prompt(metadata_row)},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return  resp.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    qa_pairs = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            question = ask_gpt(row)\n",
    "            qa_pairs.append({\n",
    "                \"question\": question,\n",
    "                \"answer\":   row[\"NCT ID\"]\n",
    "            })\n",
    "            print(f\"[{i+1}/{len(df)}] ✅ 生成完成: {row['NCT ID']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i+1}/{len(df)}] ❌ 失败: {e}\")\n",
    "        time.sleep(sleep_sec)   # 简单限速，避免 429\n",
    "\n",
    "    with open(json_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(qa_pairs, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n✨ 已生成 {len(qa_pairs)} 对问答，保存至 {json_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cba41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] ✅ 生成完成: NCT00056160\n",
      "[2/100] ✅ 生成完成: NCT00637273\n",
      "[3/100] ✅ 生成完成: NCT00262080\n",
      "[4/100] ✅ 生成完成: NCT00446680\n",
      "[5/100] ✅ 生成完成: NCT00097591\n",
      "[6/100] ✅ 生成完成: NCT00327691\n",
      "[7/100] ✅ 生成完成: NCT00117676\n",
      "[8/100] ✅ 生成完成: NCT00088530\n",
      "[9/100] ✅ 生成完成: NCT00627926\n",
      "[10/100] ✅ 生成完成: NCT00287729\n",
      "[11/100] ✅ 生成完成: NCT00403767\n",
      "[12/100] ✅ 生成完成: NCT00289640\n",
      "[13/100] ✅ 生成完成: NCT01133704\n",
      "[14/100] ✅ 生成完成: NCT00024440\n",
      "[15/100] ✅ 生成完成: NCT00530348\n",
      "[16/100] ✅ 生成完成: NCT00213135\n",
      "[17/100] ✅ 生成完成: NCT00297258\n",
      "[18/100] ✅ 生成完成: NCT00395135\n",
      "[19/100] ✅ 生成完成: NCT00152386\n",
      "[20/100] ✅ 生成完成: NCT00298038\n",
      "[21/100] ✅ 生成完成: NCT00257608\n",
      "[22/100] ✅ 生成完成: NCT00391872\n",
      "[23/100] ✅ 生成完成: NCT00364923\n",
      "[24/100] ✅ 生成完成: NCT00358150\n",
      "[25/100] ✅ 生成完成: NCT05428969\n",
      "[26/100] ✅ 生成完成: NCT00126724\n",
      "[27/100] ✅ 生成完成: NCT00530816\n",
      "[28/100] ✅ 生成完成: NCT00340834\n",
      "[29/100] ✅ 生成完成: NCT00125034\n",
      "[30/100] ✅ 生成完成: NCT00355134\n",
      "[31/100] ✅ 生成完成: NCT00287716\n",
      "[32/100] ✅ 生成完成: NCT00093158\n",
      "[33/100] ✅ 生成完成: NCT00554216\n",
      "[34/100] ✅ 生成完成: NCT00179660\n",
      "[35/100] ✅ 生成完成: NCT00000560\n",
      "[36/100] ✅ 生成完成: NCT00111319\n",
      "[37/100] ✅ 生成完成: NCT00134563\n",
      "[38/100] ✅ 生成完成: NCT00623636\n",
      "[39/100] ✅ 生成完成: NCT00364013\n",
      "[40/100] ✅ 生成完成: NCT00065442\n",
      "[41/100] ✅ 生成完成: NCT01712490\n",
      "[42/100] ✅ 生成完成: NCT00542555\n",
      "[43/100] ✅ 生成完成: NCT00567255\n",
      "[44/100] ✅ 生成完成: NCT00337103\n",
      "[45/100] ✅ 生成完成: NCT00325195\n",
      "[46/100] ✅ 生成完成: NCT00511238\n",
      "[47/100] ✅ 生成完成: NCT00135408\n",
      "[48/100] ✅ 生成完成: NCT00294723\n",
      "[49/100] ✅ 生成完成: NCT00071799\n",
      "[50/100] ✅ 生成完成: NCT00413036\n",
      "[51/100] ✅ 生成完成: NCT02873936\n",
      "[52/100] ✅ 生成完成: NCT01265849\n",
      "[53/100] ✅ 生成完成: NCT00089570\n",
      "[54/100] ✅ 生成完成: NCT00129142\n",
      "[55/100] ✅ 生成完成: NCT00333775\n",
      "[56/100] ✅ 生成完成: NCT00412984\n",
      "[57/100] ✅ 生成完成: NCT00603902\n",
      "[58/100] ✅ 生成完成: NCT00154102\n",
      "[59/100] ✅ 生成完成: NCT00321464\n",
      "[60/100] ✅ 生成完成: NCT00532779\n",
      "[61/100] ✅ 生成完成: NCT00357279\n",
      "[62/100] ✅ 生成完成: NCT00573443\n",
      "[63/100] ✅ 生成完成: NCT03566043\n",
      "[64/100] ✅ 生成完成: NCT00343564\n",
      "[65/100] ✅ 生成完成: NCT00027300\n",
      "[66/100] ✅ 生成完成: NCT00262600\n",
      "[67/100] ✅ 生成完成: NCT00215800\n",
      "[68/100] ✅ 生成完成: NCT00157209\n",
      "[69/100] ✅ 生成完成: NCT00641056\n",
      "[70/100] ✅ 生成完成: NCT00307437\n",
      "[71/100] ✅ 生成完成: NCT03207009\n",
      "[72/100] ✅ 生成完成: NCT00991211\n",
      "[73/100] ✅ 生成完成: NCT00050778\n",
      "[74/100] ✅ 生成完成: NCT00289978\n",
      "[75/100] ✅ 生成完成: NCT00099788\n",
      "[76/100] ✅ 生成完成: NCT00113607\n",
      "[77/100] ✅ 生成完成: NCT00116805\n",
      "[78/100] ✅ 生成完成: NCT00509145\n",
      "[79/100] ✅ 生成完成: NCT00467844\n",
      "[80/100] ✅ 生成完成: NCT00518882\n",
      "[81/100] ✅ 生成完成: NCT00420212\n",
      "[82/100] ✅ 生成完成: NCT00688740\n",
      "[83/100] ✅ 生成完成: NCT00454818\n",
      "[84/100] ✅ 生成完成: NCT00308139\n",
      "[85/100] ✅ 生成完成: NCT00451451\n",
      "[86/100] ✅ 生成完成: NCT00314951\n",
      "[87/100] ✅ 生成完成: NCT00274651\n",
      "[88/100] ✅ 生成完成: NCT00524277\n",
      "[89/100] ✅ 生成完成: NCT00424047\n",
      "[90/100] ✅ 生成完成: NCT00468728\n",
      "[91/100] ✅ 生成完成: NCT00318461\n",
      "[92/100] ✅ 生成完成: NCT00004205\n",
      "[93/100] ✅ 生成完成: NCT00339183\n",
      "[94/100] ✅ 生成完成: NCT00471497\n",
      "[95/100] ✅ 生成完成: NCT00071487\n",
      "[96/100] ✅ 生成完成: NCT00521053\n",
      "[97/100] ✅ 生成完成: NCT00123253\n",
      "[98/100] ✅ 生成完成: NCT00005947\n",
      "[99/100] ✅ 生成完成: NCT00590187\n",
      "[100/100] ✅ 生成完成: NCT00553787\n",
      "\n",
      "✨ 已生成 100 对问答，保存至 qa_pairs_tmp.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate_clinical_trials_qa.py\n",
    "———————————————\n",
    "Read a CSV of clinical-trial metadata, call GPT to create natural-language\n",
    "ClinicalTrials.gov questions, and save QA pairs to JSON.\n",
    "\"\"\"\n",
    "import os \n",
    "from openai import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-4jnd9yjoIXnQRQ5SXR2b3bVO1d3sHtuyegGMzAl6awSWDRNn' \n",
    "os.environ['OPENAI_BASE_URL'] = 'https://api2.aigcbest.top/v1' \n",
    "client = OpenAI()\n",
    "import os, json, time\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import openai\n",
    "\n",
    "# ========== 配置 ==========\n",
    "csv_path   = \"clinical_trials_data_complete.csv\"\n",
    "json_out   = \"qa_pairs_tmp.json\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # 或直接写明字符串\n",
    "model_name = \"gpt-4o\"                         # 也可用 gpt-3.5-turbo-0125\n",
    "sleep_sec  = 1.2                              # 速率限制：可按需要调整\n",
    "# =========================\n",
    "\n",
    "# --- 新增辅助函数 ---------------------------------------------\n",
    "def first_n_locations(loc_str, n=5):\n",
    "    \"\"\"返回 'City - Country, ...' 的前 n 项，超出部分用 'etc.' 收尾\"\"\"\n",
    "    if pd.isna(loc_str):\n",
    "        return \"\"\n",
    "    parts = [p.strip() for p in loc_str.split(\",\") if p.strip()]\n",
    "    if len(parts) > n:\n",
    "        return \", \".join(parts[:n]) + \", etc.\"\n",
    "    return \", \".join(parts)\n",
    "\n",
    "def shorten_interventions(iv_str, max_items=3):\n",
    "    \"\"\"保留 1–3 个关键干预，剩余用 'others' 表示（可选）\"\"\"\n",
    "    if pd.isna(iv_str):\n",
    "        return \"\"\n",
    "    items = [i.strip() for i in iv_str.split(\",\") if i.strip()]\n",
    "    if len(items) > max_items:\n",
    "        items = items[:max_items] + [\"others\"]\n",
    "    return \", \".join(items)\n",
    "    \n",
    "# 把日期 \"2003-01-01\" -> \"January 2003\"，\"2008-01\" -> \"2008\"\n",
    "def pretty_date(d):\n",
    "    try:\n",
    "        # 处理空值 / NaN\n",
    "        if pd.isna(d): \n",
    "            return \"\"\n",
    "        d = str(d).strip()\n",
    "        # 只有年份或“YYYY-MM”\n",
    "        if len(d) <= 7:\n",
    "            return d\n",
    "        return parser.parse(d).strftime(\"%B %Y\")\n",
    "    except Exception:\n",
    "        return d\n",
    "\n",
    "# 给 GPT 的 system 提示（一次即可，不必重复发送）\n",
    "SYSTEM_MSG = (\n",
    "    \"You create concise, natural search questions for ClinicalTrials.gov. \"\n",
    "    \"The question must:\\n\"\n",
    "    \"1. Begin with 'In ClinicalTrials.gov,' (or similar) to specify scope.\\n\"\n",
    "    \"2. Cite 3-6 key fields (status, phase, study type, start date, condition, \"\n",
    "    \"main interventions, countries/regions) that uniquely pinpoint the trial.\\n\"\n",
    "    \"3. Avoid long exhaustive lists; summarize interventions/locations clearly \"\n",
    "    \"and naturally (e.g., 'compared drug A with placebo', 'across sites in the United States and Canada').\\n\"\n",
    "    \"4. Use fluent English; no SQL-like phrasing.\\n\"\n",
    "    \"Example style: \\\"In ClinicalTrials.gov, what is the NCT number for a completed Phase 3 interventional study \"\n",
    "    \"that started in January 2003, investigated CC-5013 plus dexamethasone for multiple myeloma, and recruited \"\n",
    "    \"patients in both the United States and Canada?\\\"\\n\"\n",
    "    \"Return ONLY the single-sentence question.\"\n",
    ")\n",
    "\n",
    "def build_user_prompt(row):\n",
    "    fields = {\n",
    "        \"NCT_ID\":         row[\"NCT ID\"],\n",
    "        \"Overall_Status\": row[\"Overall Status\"],\n",
    "        \"Phase\":          row.get(\"Phases\", \"\"),\n",
    "        \"Study_Type\":     row.get(\"Study Type\", \"\"),\n",
    "        \"Start_Date\":     pretty_date(row[\"Start Date\"]),\n",
    "        \"Conditions\":     row[\"Conditions\"],\n",
    "        \"Interventions\":  shorten_interventions(row[\"Interventions\"]),\n",
    "        \"Locations\":      first_n_locations(row[\"Locations\"], n=5),\n",
    "    }\n",
    "    return (\n",
    "        \"Write ONE natural-language question that would let a person retrieve \"\n",
    "        \"this exact clinical trial on ClinicalTrials.gov. Use the metadata JSON below; \"\n",
    "        \"do NOT mention the NCT_ID, keep it concise.\\n\\n\"\n",
    "        f\"metadata = {json.dumps(fields, ensure_ascii=False)}\"\n",
    "    )\n",
    "\n",
    "def ask_gpt(metadata_row):\n",
    "    \"\"\"向 GPT 发送聊天消息并返回问题字符串\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "            {\"role\": \"user\",   \"content\": build_user_prompt(metadata_row)},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return  resp.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    qa_pairs = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            question = ask_gpt(row)\n",
    "            qa_pairs.append({\n",
    "                \"question\": question,\n",
    "                \"answer\":   row[\"NCT ID\"]\n",
    "            })\n",
    "            print(f\"[{i+1}/{len(df)}] ✅ 生成完成: {row['NCT ID']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i+1}/{len(df)}] ❌ 失败: {e}\")\n",
    "        time.sleep(sleep_sec)   # 简单限速，避免 429\n",
    "\n",
    "    with open(json_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(qa_pairs, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n✨ 已生成 {len(qa_pairs)} 对问答，保存至 {json_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57769f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/ctgov_tool.py\n",
    "import os, requests\n",
    "\n",
    "BASE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "\n",
    "def ctgov_search(filter_expr: str, page_size: int = 100) -> list[str]:\n",
    "    \"\"\"\n",
    "    Call ClinicalTrials.gov v2 search.\n",
    "    `filter_expr` 一般形如:\n",
    "        \"overallStatus=Completed;conditions=Multiple+Myeloma;phases=Phase+3\"\n",
    "    返回符合条件的 NCT_ID 列表（最多 page_size 条）。\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"filter\": filter_expr,\n",
    "        \"pageSize\": page_size,\n",
    "        # 还可以加 sort, include etc.\n",
    "    }\n",
    "    r = requests.get(BASE, params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    studies = r.json().get(\"studies\", [])\n",
    "    return [s[\"protocolSection\"][\"identificationModule\"][\"nctId\"]\n",
    "            for s in studies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/ctgov_schema.py\n",
    "ctgov_schema = {\n",
    "    \"name\": \"ctgov_search\",\n",
    "    \"description\": (\n",
    "        \"Search ClinicalTrials.gov v2 and return a list of NCT IDs that match \"\n",
    "        \"the given filter expression.\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"filter_expr\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": (\n",
    "                    \"Semicolon-separated filter expression, e.g. \"\n",
    "                    \"\\\"overallStatus=Completed;conditions=Multiple+Myeloma;phases=Phase+3\\\"\"\n",
    "                )\n",
    "            },\n",
    "            \"page_size\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Maximum number of studies to return\",\n",
    "                \"default\": 100\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"filter_expr\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fc1316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610c9c5efdb349899f48d0aeb93bb7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building QA:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 100 samples → ctgov_qa_dataset.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build_ctgov_qa_dataset_one_call_minimal_filter.py\n",
    "-------------------------------------------------\n",
    "Single GPT call returns question & filter_expr.\n",
    "Only the constraints mentioned in question are kept.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, re, hashlib, pandas as pd\n",
    "from dateutil import parser\n",
    "from openai import AzureOpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------- Azure OpenAI ----------\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]  = \"5a1437f6ff2648b9b969507fb5a73276\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-mistraleastus2753718354821.openai.azure.com/\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key       = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version   = \"2024-12-01-preview\",\n",
    "    azure_endpoint= os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "MODEL      = \"gpt-4.1-noah\"\n",
    "CSV_PATH   = \"../source/clinical_trials_data_complete.csv\"\n",
    "OUT_JSON   = \"ctgov_qa_dataset.json\"\n",
    "SLEEP_SEC  = 1.0                 # 简单限速\n",
    "\n",
    "# ---------- helper ----------\n",
    "def pretty_date(d):\n",
    "    try:\n",
    "        if pd.isna(d): return \"\"\n",
    "        return parser.parse(str(d)).strftime(\"%B %Y\")\n",
    "    except Exception:\n",
    "        return str(d)\n",
    "\n",
    "SYSTEM_MSG = (\n",
    "    \"You are given structured metadata of a clinical trial. \"\n",
    "    \"Return a JSON object with exactly two keys:\\n\\n\"\n",
    "    \"1) `question`  – ONE concise English question that starts with \"\n",
    "    \"\\\"In ClinicalTrials.gov,\\\" and **explicitly** states some (not all) of: \"\n",
    "    \"status, phase, study type, start month+year, condition(s), main intervention,\"\n",
    "    \" and at least one country. Do NOT reveal the NCT ID.\\n\\n\"\n",
    "    \"2) `filter_expr` – a ClinicalTrials.gov v2 filter string that contains \"\n",
    "    \"**only** those keys that your question explicitly mentioned. \"\n",
    "    \"Use keys: overallStatus, phases, studyType, conditions, interventions.name, \"\n",
    "    \"startDateFrom (YYYY-MM-01), locations.country.  \"\n",
    "    \"If a key is NOT mentioned verbatim or semantically in the question, DO NOT include it. \"\n",
    "    \"Separate pairs with semicolons.  \\n\\n\"\n",
    "    \"Return ONLY the JSON.\"\n",
    ")\n",
    "\n",
    "def gpt_generate(row: pd.Series) -> dict:\n",
    "    user_msg = (\n",
    "        f\"status={row['Overall Status']}; \"\n",
    "        f\"phase={row['Phases']}; \"\n",
    "        f\"type={row['Study Type']}; \"\n",
    "        f\"start={pretty_date(row['Start Date'])}; \"\n",
    "        f\"conditions={row['Conditions']}; \"\n",
    "        f\"interventions={row['Interventions'][:120]}; \"\n",
    "        f\"locations={row['Locations'][:120]}\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model   = MODEL,\n",
    "        messages=[{\"role\":\"system\", \"content\": SYSTEM_MSG},\n",
    "                  {\"role\":\"user\",   \"content\": user_msg}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# ---------- 自动校验 & 精简 ----------\n",
    "# 映射：filter 键 -> 判断其是否在 question 中出现的 regex\n",
    "REGEX_MAP = {\n",
    "    \"overallStatus\":      r\"(Completed|Recruiting|Active,? not recruiting|Unknown status|Suspended|Terminated)\",\n",
    "    \"phases\":             r\"(Phase\\s*0|Phase\\s*1/2|Phase\\s*1|Phase\\s*2/3|Phase\\s*2|Phase\\s*3|Phase\\s*4)\",\n",
    "    \"studyType\":          r\"(Interventional|Observational|Expanded Access)\",\n",
    "    \"conditions\":         r\"(?:[A-Z][a-zA-Z0-9\\- ]+)\",\n",
    "    \"interventions.name\": r\"(?:[A-Z][a-zA-Z0-9\\-\\+ ]+)\",\n",
    "    \"startDateFrom\":      r\"(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\",\n",
    "    \"locations.country\":  r\"(United States|Canada|China|Japan|France|Germany|Italy|Spain|United Kingdom|Australia|Mexico|Brazil|India)\"\n",
    "}\n",
    "\n",
    "def trim_filter_expr(question: str, filter_expr: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove key=value pairs whose key is not actually mentioned in the question.\n",
    "    \"\"\"\n",
    "    kept = []\n",
    "    for pair in filter_expr.split(\";\"):\n",
    "        if \"=\" not in pair: \n",
    "            continue\n",
    "        key, val = pair.split(\"=\", 1)\n",
    "        key = key.strip()\n",
    "        regex = REGEX_MAP.get(key)\n",
    "        if not regex:\n",
    "            continue\n",
    "        if re.search(regex, question, flags=re.I):\n",
    "            kept.append(pair.strip())\n",
    "    return \";\".join(kept)\n",
    "\n",
    "# ---------- build dataset ----------\n",
    "df      = pd.read_csv(CSV_PATH)\n",
    "samples = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building QA\"):\n",
    "    try:\n",
    "        data   = gpt_generate(row)\n",
    "        q      = data[\"question\"].strip()\n",
    "        filt   = data[\"filter_expr\"].strip()\n",
    "\n",
    "        # 加前缀双保险\n",
    "        if not q.lower().startswith(\"in clinicaltrials.gov\"):\n",
    "            q = \"In ClinicalTrials.gov, \" + q[0].lower() + q[1:]\n",
    "\n",
    "        # ▶ 自动精简，确保完全对齐\n",
    "        filt = trim_filter_expr(q, filt)\n",
    "\n",
    "        samples.append({\n",
    "            \"id\": hashlib.md5(filt.encode()).hexdigest()[:16],\n",
    "            \"question\": q,\n",
    "            \"tool_calls\": [{\n",
    "                \"tool\": \"ctgov_search\",\n",
    "                \"params\": {\"filter_expr\": filt, \"page_size\": 100}\n",
    "            }],\n",
    "            \"answer\": [row[\"NCT ID\"]]\n",
    "        })\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"⚠️  {row['NCT ID']} failed: {e}\")\n",
    "\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"dataset\": samples}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(samples)} samples → {OUT_JSON}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
