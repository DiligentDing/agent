{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a4ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql, random, logging\n",
    "import networkx as nx\n",
    "from typing import Set, Union,Dict, List, Iterable\n",
    "import pandas as pd\n",
    "# ---------- 0. 数据源 ----------\n",
    "DB_CFG = dict(\n",
    "    host=\"172.188.121.85\", port=3306,\n",
    "    user=\"root\", password=\"1qaz0plm\",\n",
    "    database=\"umls\",\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac7af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_LIST = [\n",
    "    {\n",
    "        \"id\": \"Symptom_Disease_Drug_Target\",\n",
    "        \"steps\": [\n",
    "            {   # ① 起点：临床表现\n",
    "                \"stype\": [\"T184\"],                 # Sign or Symptom\n",
    "                \"as\": \"Symptom\",\n",
    "                \"rela\":[]\n",
    "            },\n",
    "            {   # ② 由该症状提示的疾病\n",
    "                \"rela\": [\"manifestation_of\"],      # CUI1(Symptom) → CUI2(Disease)\n",
    "                \"stype\": [\"T047\"],                 # Disease or Syndrome\n",
    "                \"as\": \"Disease or Syndrome\"\n",
    "            },\n",
    "            {   # ③ 疾病可被哪些药理物质治疗\n",
    "                \"rela\": [\"may_be_treated_by\"],     # CUI1(Disease) → CUI2(Pharm. Substance)\n",
    "                \"stype\": [\"T121\", \"T109\"],          # Pharmacologic Substance\n",
    "                \"as\": \"Pharmacologic Substance\"\n",
    "            },\n",
    "            {   # ④ 该药物的主要分子靶点\n",
    "                \"rela\": [\"has_target\"],            # CUI1(Pharm.) → CUI2(Protein)\n",
    "                \"stype\": [\"T116\", \"T126\", \"T192\"], # Amino Acid, Peptide, or Protein\n",
    "                \"as\": \"Protein Target\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "819e54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_LIST=[\n",
    "{\n",
    "    \"id\": \"Disease_Drug_Target\",\n",
    "    \"steps\": [\n",
    "        {   \"stype\": [\"T047\"],                 # Disease or Syndrome   # 5854\n",
    "            \"as\": \"Disease or Syndrome\",\n",
    "            \"rela\":[]\n",
    "        },\n",
    "        {   # ③ 疾病可被哪些药理物质治疗\n",
    "            \"rela\": [\"may_be_treated_by\"],     # CUI1(Disease) → CUI2(Pharm. Substance)\n",
    "            \"stype\": [\"T121\",\"T109\"],                 # Pharmacologic Substance  #7101\n",
    "            \"as\": \"Pharmacologic Substance\"\n",
    "        },\n",
    "        {   # ④ 该药物的主要分子靶点\n",
    "            \"rela\": [\"has_target\"],            # CUI1(Pharm.) → CUI2(Protein)\n",
    "            \"stype\": [\"T116\",\"T126\",\"T192\"],                 # Amino Acid, Peptide, or Protein # 4894+1859+1699\n",
    "            \"as\": \"Protein Target\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f09c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_LIST=[{\n",
    "    \"id\": \"Disease_Drug_moA\",\n",
    "    \"steps\": [\n",
    "        {   \"stype\": [\"T047\"],                 # Disease or Syndrome   # 5854\n",
    "            \"as\": \"Disease or Syndrome\",\n",
    "            \"rela\":[]\n",
    "        },\n",
    "        {   # ③ 疾病可被哪些药理物质治疗\n",
    "            \"rela\": [\"may_be_treated_by\"],     # CUI1(Disease) → CUI2(Pharm. Substance)\n",
    "            \"stype\": [\"T121\",\"T109\"],                 # Pharmacologic Substance  #7101\n",
    "            \"as\": \"Pharmacologic Substance\"\n",
    "        },\n",
    "        {   # ② 作用机制（分子功能）\n",
    "            \"rela\": [\"has_mechanism_of_action\"],\n",
    "            \"stype\": [\"T044\"],                  # Molecular Function\n",
    "            \"as\": \"Molecular Function\"\n",
    "        }\n",
    "    ]\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df6635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一次查询不超过这么多占位符\n",
    "CHUNK_SIZE = 1000         # 1000 × 20 字节 ≈ 20 KB，远低于 max_allowed_packet\n",
    "import math\n",
    "def load_cui2tui(cui_set: Set[str], chunk: int = CHUNK_SIZE) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    仅查询参与边的 CUI → TUI；大集合自动分块，避免超过 max_allowed_packet\n",
    "    \"\"\"\n",
    "    if not cui_set:\n",
    "        return {}\n",
    "\n",
    "    tui_map: Dict[str, List[str]] = {}\n",
    "\n",
    "    cui_list = list(cui_set)\n",
    "    n_chunks = math.ceil(len(cui_list) / chunk)\n",
    "\n",
    "    with pymysql.connect(**DB_CFG) as conn, conn.cursor(pymysql.cursors.DictCursor) as cur:\n",
    "        for i in range(n_chunks):\n",
    "            batch = cui_list[i * chunk : (i + 1) * chunk]\n",
    "            fmt   = \",\".join([\"%s\"] * len(batch))\n",
    "            sql   = f\"SELECT CUI, TUI FROM MRSTY WHERE CUI IN ({fmt})\"\n",
    "            cur.execute(sql, batch)\n",
    "\n",
    "            for r in cur.fetchall():\n",
    "                tui_map.setdefault(r[\"CUI\"], []).append(r[\"TUI\"])\n",
    "\n",
    "    return tui_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ceeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cui2str(cui_set: Set[str]) -> Dict[str, str]:\n",
    "    if not cui_set:\n",
    "        return {}\n",
    "\n",
    "    placeholders = \",\".join([\"%s\"] * len(cui_set))\n",
    "    sql = f\"\"\"\n",
    "        SELECT CUI, STR, TTY\n",
    "        FROM   MRCONSO\n",
    "        WHERE  LAT='ENG' AND CUI IN ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    str_map = {}\n",
    "    with pymysql.connect(**DB_CFG) as conn, conn.cursor(pymysql.cursors.DictCursor) as cur:\n",
    "        cur.execute(sql, list(cui_set))\n",
    "        for row in cur.fetchall():\n",
    "            cui, str_, tty = row[\"CUI\"], row[\"STR\"], row[\"TTY\"]\n",
    "            # 先记录 PF/PT，否则保留第一条\n",
    "            if tty in (\"PF\", \"PT\") or cui not in str_map:\n",
    "                str_map[cui] = str_\n",
    "\n",
    "    return str_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677919a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edges(rela_set: Iterable[str]):\n",
    "    \"\"\"\n",
    "    只拉取模板需要的关系，返回包含 (CUI1, CUI2, REL, RELA) 的记录列表\n",
    "    \"\"\"\n",
    "    fmt = \",\".join([\"%s\"] * len(rela_set))\n",
    "    sql = f\"\"\"\n",
    "        SELECT CUI1, CUI2, REL, RELA\n",
    "        FROM MRREL\n",
    "        WHERE RELA IN ({fmt})\n",
    "    \"\"\"\n",
    "    with pymysql.connect(**DB_CFG) as conn, conn.cursor(pymysql.cursors.DictCursor) as cur:\n",
    "        cur.execute(sql, tuple(rela_set))\n",
    "        return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e879f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(rela_set: Set[str]) -> nx.MultiDiGraph:\n",
    "    \"\"\"\n",
    "    构建 MultiDiGraph，并给每个节点写入两项属性：\n",
    "        - tui: List[str]\n",
    "        - str: 英文首选术语 (若缺则用 CUI 兜底)\n",
    "    \"\"\"\n",
    "    # 1) 批量加载边\n",
    "    edges = load_edges(rela_set)\n",
    "\n",
    "    # 2) 收集所有出现的 CUI\n",
    "    cui_set: Set[str] = {e[\"CUI1\"] for e in edges} | {e[\"CUI2\"] for e in edges}\n",
    "\n",
    "    # 3) 一次性查询 TUI 和 STR\n",
    "    tui_map = load_cui2tui(cui_set)\n",
    "    str_map = load_cui2str(cui_set)\n",
    "\n",
    "    # 4) 构图\n",
    "    G = nx.MultiDiGraph()\n",
    "    for e in edges:\n",
    "        G.add_edge(\n",
    "            e[\"CUI2\"],\n",
    "            e[\"CUI1\"],\n",
    "            rela=e[\"RELA\"] or e[\"REL\"]              # UMLS 中有的用 RELA，有的用 REL\n",
    "        )\n",
    "\n",
    "    # 5) 批量补节点属性\n",
    "    for cui in G.nodes:\n",
    "        G.nodes[cui][\"tui\"] = tui_map.get(cui, [])\n",
    "        G.nodes[cui][\"str\"] = str_map.get(cui, cui)   # 查不到时直接用 CUI\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9921b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_semtype(node_tuis: List[str], allowed_tui: List[str]) -> bool:\n",
    "    return any(tui in allowed_tui for tui in node_tuis)\n",
    "\n",
    "def sample_one(\n",
    "        G: nx.MultiDiGraph,\n",
    "        tpl_steps: List[Dict],\n",
    "        max_attempts: int = 50_000\n",
    "    ) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    随模板随机采 1 条路径。若采样失败，回退到上一步并继续尝试，而不是从头开始。\n",
    "    节点属性要求已包含：\n",
    "        - tui : List[str]\n",
    "        - str : 可读名称（若缺自动兜底成 CUI）\n",
    "    返回:\n",
    "        {\n",
    "          \"cuis\":      [CUI0, CUI1, ...],\n",
    "          \"relas\":     [rela0, rela1, ...],            # len = len(cuis) - 1\n",
    "          \"path_strs\": [STR0, rela0, STR1, ...]        # 交错拼接，可直接打印\n",
    "        }\n",
    "    \"\"\"\n",
    "    # ---------- 1) 找所有可能的起点 ----------\n",
    "    step0 = tpl_steps[0]\n",
    "    cand_start = [\n",
    "        n for n, d in G.nodes(data=True)\n",
    "        if has_semtype(d[\"tui\"], step0[\"stype\"])\n",
    "    ]\n",
    "    if not cand_start:\n",
    "        raise RuntimeError(\"No start node matches TUI constraint.\")\n",
    "\n",
    "    # ---------- 2) 多次尝试直到成功 ----------\n",
    "    for _ in range(max_attempts):\n",
    "        src = random.choice(cand_start)\n",
    "        path = [src]  # CUI 序列\n",
    "        relas = []  # 关系序列\n",
    "        cur = src\n",
    "        history = [(src, None)]  # 保存路径和对应的边\n",
    "\n",
    "        # 从第二步开始尝试\n",
    "        for step_idx, step in enumerate(tpl_steps[1:], start=1):\n",
    "            # 过滤满足\"关系 + 目标节点 TUI\" 的出边\n",
    "            nxt_edges = [\n",
    "                (v, edata[\"rela\"])\n",
    "                for _, v, edata in G.out_edges(cur, data=True)\n",
    "                if edata[\"rela\"] in step[\"rela\"]\n",
    "                and has_semtype(G.nodes[v][\"tui\"], step[\"stype\"])\n",
    "            ]\n",
    "            if not nxt_edges:\n",
    "                if history:\n",
    "                    # 回退到上一步\n",
    "                    cur, _ = history.pop()\n",
    "                    path = path[:len(path)-1]\n",
    "                    if relas:\n",
    "                        relas = relas[:len(relas)-1]\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            v, rela = random.choice(nxt_edges)\n",
    "            cur = v\n",
    "            path.append(cur)\n",
    "            relas.append(rela)\n",
    "            history.append((cur, rela))  # 记录当前节点和关系\n",
    "\n",
    "        # 检查路径是否完整\n",
    "        if len(path) == len(tpl_steps):\n",
    "            # 交错拼装可读路径\n",
    "            path_strs = []\n",
    "            for i, cui in enumerate(path):\n",
    "                node_str = G.nodes[cui].get(\"str\", cui)\n",
    "                path_strs.append(node_str)\n",
    "                if i < len(relas):\n",
    "                    path_strs.append(relas[i])  # 插入当前边\n",
    "\n",
    "            return {\n",
    "                \"cuis\": path,\n",
    "                \"relas\": relas,\n",
    "                \"path_strs\": path_strs\n",
    "            }\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"No path found after {max_attempts} random starts. \"\n",
    "        \"Consider relaxing template or increasing attempts.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013849ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph with relationships: {'manifestation_of', 'may_be_treated_by', 'has_target'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# 收集所有 rela 以便一次性建图\n",
    "# 只收集非空的关系\n",
    "# 跳过第一步，因为第一步是起点，不需要入边\n",
    "needed_rela = set()\n",
    "for tpl in TEMPLATE_LIST:\n",
    "    for step in tpl[\"steps\"][1:]:  # 从第二步开始（索引1）\n",
    "        if \"rela\" in step and step[\"rela\"]:  # 确保有rela字段且非空\n",
    "            for r in step[\"rela\"]:\n",
    "                if r:  # 只添加非空关系\n",
    "                    needed_rela.add(r)\n",
    "\n",
    "\n",
    "print(f\"Building graph with relationships: {needed_rela}\")\n",
    "G = build_graph(needed_rela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9968fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7271, 22421)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f95e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only got 14 unique paths (wanted 20) after 100 attempts\n"
     ]
    }
   ],
   "source": [
    "import json, logging, random\n",
    "\n",
    "UNIQUE_TRIES = 100    # 每个模板最多尝试多少次采样\n",
    "N_PATHS       = 20  # 每个模板想要保留的唯一条数\n",
    "\n",
    "def sample_unique_paths(G, tpl_steps, want=N_PATHS, max_tries=UNIQUE_TRIES):\n",
    "    \"\"\"返回去重后的路径列表（每条为 node-list）\"\"\"\n",
    "    paths, seen = [], set()\n",
    "\n",
    "    tries = 0\n",
    "    while len(paths) < want and tries < max_tries:\n",
    "        tries += 1\n",
    "        try:\n",
    "            p = sample_one(G, tpl_steps)        # ← 你的随机采样函数\n",
    "        except RuntimeError as e:\n",
    "            logging.warning(\"sample_one failed: %s\", e)\n",
    "            continue\n",
    "\n",
    "        key = tuple(p[\"path_strs\"])  # or tuple(p) / make_edge_key(p)\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            paths.append(p)\n",
    "\n",
    "    if len(paths) < want:\n",
    "        logging.warning(\n",
    "            \"Only got %d unique paths (wanted %d) after %d attempts\",\n",
    "            len(paths), want, tries\n",
    "        )\n",
    "    return paths\n",
    "\n",
    "out = {}\n",
    "for tpl in TEMPLATE_LIST:\n",
    "    out[tpl[\"id\"]] = sample_unique_paths(G, tpl[\"steps\"])\n",
    "\n",
    "with open(\"sampled_paths.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(out, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c58fc777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== 模板: Disease_Drug_moA =====\n",
      "\n",
      "Total paths: 1500\n",
      "Path lengths distribution: [3]\n",
      "Length 3: 1500 paths (100.00%)\n",
      "\n",
      "✅ 所有路径均完整 (长度 = 3)\n",
      "\n",
      "成功路径示例:\n",
      "\n",
      "路径 1:\n",
      "Granuloma inguinale -> may_be_treated_by -> Doxycycline anhydrous -> has_mechanism_of_action -> Protein Synthesis Inhibitors\n",
      "\n",
      "路径 2:\n",
      "Ascariasis -> may_be_treated_by -> Pyrantel-containing product -> has_mechanism_of_action -> Cholinesterase Inhibitors\n",
      "\n",
      "路径 3:\n",
      "Infection by Fascioloides -> may_be_treated_by -> Emetine Hydrochloride -> has_mechanism_of_action -> Unknown Cellular or Molecular Interaction\n"
     ]
    }
   ],
   "source": [
    "# 路径完整性检查与分析\n",
    "def analyze_paths(out):\n",
    "    \"\"\" 分析生成路径的完整性和统计信息 \"\"\"\n",
    "    for tpl_id, paths in out.items():\n",
    "        print(f\"\\n\\n===== 模板: {tpl_id} =====\\n\")\n",
    "        \n",
    "        # 路径长度分析\n",
    "        path_lens = [len(p['cuis']) for p in paths]\n",
    "        print(f\"Total paths: {len(paths)}\")\n",
    "        print(f\"Path lengths distribution: {sorted(set(path_lens))}\")\n",
    "        for length in sorted(set(path_lens)):\n",
    "            count = path_lens.count(length)\n",
    "            print(f\"Length {length}: {count} paths ({count/len(paths):.2%})\")\n",
    "        \n",
    "        # 检查路径完整性 - 每个模板应有的长度\n",
    "        expected_len = len(next(tpl['steps'] for tpl in TEMPLATE_LIST if tpl['id'] == tpl_id))\n",
    "        incomplete = [p for p in paths if len(p['cuis']) != expected_len]\n",
    "        if incomplete:\n",
    "            print(f\"\\n\\u8b66告: 发现 {len(incomplete)} 条不完整路径 (期望长度 {expected_len})!\")\n",
    "            # 显示前3条不完整路径示例\n",
    "            for i, p in enumerate(incomplete[:3]):\n",
    "                print(f\"\\n不完整路径示例 {i+1}:\")\n",
    "                print(f\"CUIs: {p['cuis']}\")\n",
    "                print(f\"Relationships: {p['relas']}\")\n",
    "                print(f\"Path as text: {' -> '.join(p['path_strs'])}\")\n",
    "        else:\n",
    "            print(f\"\\n✅ 所有路径均完整 (长度 = {expected_len})\")\n",
    "        \n",
    "        # 成功路径示例\n",
    "        print(\"\\n成功路径示例:\")\n",
    "        complete_paths = [p for p in paths if len(p['cuis']) == expected_len]\n",
    "        for i, p in enumerate(complete_paths[:3]):\n",
    "            print(f\"\\n路径 {i+1}:\")\n",
    "            print(' -> '.join(p['path_strs']))\n",
    "\n",
    "# 采样后进行路径分析\n",
    "try:\n",
    "    analyze_paths(out)\n",
    "except NameError:\n",
    "    print(\"\\n请先运行采样代码 (sample_unique_paths) 生成路径数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "131450ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并完成，共 2 个模板，2068 条路径 -> merged_paths.json\n",
      "  - Symptom_Disease_Drug_Target: 568 条路径\n",
      "  - Disease_Drug_moA: 1500 条路径\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "merge_json_files.py\n",
    "\n",
    "将 sampled_1.json 与 sampled_2.json 合并为 merged_paths.json。\n",
    "保持各自的结构，合并相同键下的数据，并去除重复项。\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def main():\n",
    "    # 文件路径\n",
    "    in1 = Path(\"sampled_1.json\")\n",
    "    in2 = Path(\"sampled_2.json\")\n",
    "    out = Path(\"merged_paths.json\")\n",
    "    \n",
    "    # 加载JSON文件\n",
    "    data1 = load_json(in1)\n",
    "    data2 = load_json(in2)\n",
    "    \n",
    "    # 初始化合并结果\n",
    "    merged_data = defaultdict(list)\n",
    "    \n",
    "    # 合并逻辑\n",
    "    # 首先处理第一个文件\n",
    "    for template_id, paths in data1.items():\n",
    "        for path in paths:\n",
    "            merged_data[template_id].append(path)\n",
    "    \n",
    "    # 然后合并第二个文件，同时去重\n",
    "    for template_id, paths in data2.items():\n",
    "        if template_id not in merged_data:\n",
    "            merged_data[template_id] = paths\n",
    "            continue\n",
    "            \n",
    "        # 使用集合来跟踪已存在的路径\n",
    "        seen_paths = set()\n",
    "        for path in merged_data[template_id]:\n",
    "            # 创建可哈希的键\n",
    "            key = (\n",
    "                tuple(path.get(\"cuis\", [])), \n",
    "                tuple(path.get(\"relas\", [])), \n",
    "                tuple(path.get(\"path_strs\", []))\n",
    "            )\n",
    "            seen_paths.add(key)\n",
    "        \n",
    "        # 添加新的不重复路径\n",
    "        for path in paths:\n",
    "            key = (\n",
    "                tuple(path.get(\"cuis\", [])), \n",
    "                tuple(path.get(\"relas\", [])), \n",
    "                tuple(path.get(\"path_strs\", []))\n",
    "            )\n",
    "            if key not in seen_paths:\n",
    "                merged_data[template_id].append(path)\n",
    "                seen_paths.add(key)\n",
    "    \n",
    "    # 将结果写入新文件\n",
    "    with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 打印统计信息\n",
    "    total_paths = sum(len(paths) for paths in merged_data.values())\n",
    "    print(f\"合并完成，共 {len(merged_data)} 个模板，{total_paths} 条路径 -> {out}\")\n",
    "    \n",
    "    # 打印每个模板的路径数\n",
    "    for template_id, paths in merged_data.items():\n",
    "        print(f\"  - {template_id}: {len(paths)} 条路径\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
